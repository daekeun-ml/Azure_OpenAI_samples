{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [TTS] Create Custom Speech Model for Vietnamese Language\n",
    "This sample demonstrates how to create Custom Speech model calling REST API. \n",
    "\n",
    "> ✨ ***Note*** <br>\n",
    "> Please check the custom speech support for each language before you get started - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#:~:text=Custom%20speech%20support \n",
    "\n",
    "## Prerequisites\n",
    "Git clone the repository to your local machine. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "* A subscription key for the Speech service. See [Try the speech service for free](https://docs.microsoft.com/azure/cognitive-services/speech-service/get-started).\n",
    "* Python 3.5 or later needs to be installed. Downloads are available [here](https://www.python.org/downloads/).\n",
    "* The Python Speech SDK package is available for Windows (x64 or x86) and Linux (x64; Ubuntu 16.04 or Ubuntu 18.04).\n",
    "* On Ubuntu 16.04 or 18.04, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install libssl1.0.0 libasound2\n",
    "  ```\n",
    "* On Debian 9, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install libssl1.0.2 libasound2\n",
    "  ```\n",
    "* On Windows you need the [Microsoft Visual C++ Redistributable for Visual Studio 2017](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads) for your platform.\n",
    "\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f887fbd-1b47-419e-869d-c0cc421a883e d44c77c4-08b0-4851-aa97-a1417aa3ddc4\n"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from utils.common import *\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "speech_key = os.getenv(\"AZURE_AI_SPEECH_API_KEY\")\n",
    "speech_region = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "\n",
    "custom_model_with_plain_id = \"\"\n",
    "custom_model_with_zip_id = \"\"\n",
    "%store -r custom_model_with_plain_id\n",
    "%store -r custom_model_with_zip_id\n",
    "\n",
    "try:\n",
    "    custom_model_with_plain_id, custom_model_with_zip_id\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the previous notebook again.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "print(custom_model_with_plain_id, custom_model_with_zip_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy of the base speech model\n",
    "- In order to learn how to quantitatively measure and improve the accuracy of the base speech to text model or your own custom models check this link\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-speech-evaluate-data?pivots=speech-cli#create-a-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the word error rate (WER) of a base model in Azure AI’s Speech service, follow these steps:\n",
    "\n",
    "Sign in to the Speech Studio:\n",
    "Go to the Azure Speech Studio.\n",
    "Create a Test:\n",
    "Navigate to Custom speech and select your project.\n",
    "Go to Test models and click on Create new test.\n",
    "Select Evaluate accuracy and click Next.\n",
    "Choose an audio + human-labeled transcription dataset. If you don’t have any datasets, upload them in the Speech datasets menu.\n",
    "Select up to two models to evaluate, then click Next.\n",
    "Enter the test name and description, then click Next.\n",
    "Review the test details and click Save and close.\n",
    "Get Test Results:\n",
    "After the test is complete, indicated by the status set to Succeeded, you will see the results, including the WER for each tested model.\n",
    "Evaluate WER:\n",
    "WER is calculated as the sum of insertion, deletion, and substitution errors divided by the total number of words in the reference transcript, multiplied by 100 to get a percentage1.\n",
    "For more detailed instructions, you can refer to this link - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-speech-evaluate-data?pivots=rest-api.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Base URL for the Speech Services REST API\n",
    "base_url = f'https://{speech_region}.api.cognitive.microsoft.com/speechtotext'\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': speech_key,\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the custom speech model ids to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2f887fbd-1b47-419e-869d-c0cc421a883e d44c77c4-08b0-4851-aa97-a1417aa3ddc4\n"
     ]
    }
   ],
   "source": [
    "# Set the base, custom model id to evaluate\n",
    "base_model_id = \"your base model id\"  ##check the model id from the train a new model ()\n",
    "print(custom_model_with_plain_id, custom_model_with_zip_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an evaulation project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created with ID: 9e8258ee-d82a-4d69-8d9f-18e3a5a8641d\n"
     ]
    }
   ],
   "source": [
    "display_name = \"Evaluation Project by raw data\"\n",
    "description = \"Project for evaluating the Vietnamese base model\"\n",
    "locale = \"vi-VN\"\n",
    "project_id = create_project(base_url, headers, display_name, description, locale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload zip files to a storage account and generate content urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded successfully.\n",
      "uploaded_files: ['Call17', 'Call18', 'Call19']\n",
      "url: {'Call17': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call17.zip?se=2024-11-08T10%3A10%3A55Z&sp=r&sv=2024-11-04&sr=b&sig=t3h69r1N/DI%2BnEBULS%2BZ553QshgCx7%2BpL5xUCheeemc%3D', 'Call18': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call18.zip?se=2024-11-08T10%3A10%3A56Z&sp=r&sv=2024-11-04&sr=b&sig=kkOhZzZ6sSN%2Bcm1pUNyUFH48oTWimGUezgmjzcITHlY%3D', 'Call19': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call19.zip?se=2024-11-08T10%3A10%3A56Z&sp=r&sv=2024-11-04&sr=b&sig=a3xb6aA96LV05wzzssDnBBUi%2BKKI7mpeGYpWcIqUBVY%3D'}\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, generate_blob_sas, BlobSasPermissions\n",
    "import os\n",
    "import datetime\n",
    "data_folder = \"eval_dataset\"\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_STORAGE_CONTAINER_NAME\")\n",
    "\n",
    "uploaded_files, url = upload_dataset_to_storage(data_folder, container_name, account_name, account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with ID: d7b282eb-5adf-441a-a440-fc36b38646fa\n",
      "Dataset created with ID: 09d2d9bd-1080-4252-9107-083e3240edf8\n",
      "Dataset created with ID: 4f199347-ac43-4a35-a84c-37e1d0015ee3\n"
     ]
    }
   ],
   "source": [
    "kind=\"Acoustic\"\n",
    "description = \"Dataset for evaluation the Vietnamese base model\"\n",
    "locale = \"vi-VN\"\n",
    "dataset_id = {}\n",
    "\n",
    "for display_name in uploaded_files:\n",
    "    dataset_id[display_name] = create_dataset(base_url, headers, project_id, url[display_name], kind, display_name, description, locale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy of the trained Custom Speech model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "9e8258ee-d82a-4d69-8d9f-18e3a5a8641d d7b282eb-5adf-441a-a440-fc36b38646fa 2f887fbd-1b47-419e-869d-c0cc421a883e d44c77c4-08b0-4851-aa97-a1417aa3ddc4\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2f887fbd-1b47-419e-869d-c0cc421a883e'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/d44c77c4-08b0-4851-aa97-a1417aa3ddc4'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/d7b282eb-5adf-441a-a440-fc36b38646fa'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/9e8258ee-d82a-4d69-8d9f-18e3a5a8641d'}, 'displayName': 'vi_eval_plain_vs_zip_Call17', 'description': 'evaluate the Vietnamese base model', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: fbe8511c-3e61-4112-9ed1-fd72cd76c529\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "9e8258ee-d82a-4d69-8d9f-18e3a5a8641d 09d2d9bd-1080-4252-9107-083e3240edf8 2f887fbd-1b47-419e-869d-c0cc421a883e d44c77c4-08b0-4851-aa97-a1417aa3ddc4\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2f887fbd-1b47-419e-869d-c0cc421a883e'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/d44c77c4-08b0-4851-aa97-a1417aa3ddc4'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/09d2d9bd-1080-4252-9107-083e3240edf8'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/9e8258ee-d82a-4d69-8d9f-18e3a5a8641d'}, 'displayName': 'vi_eval_plain_vs_zip_Call18', 'description': 'evaluate the Vietnamese base model', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 26c591c9-c0e3-4753-9765-bb28092da5f7\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "9e8258ee-d82a-4d69-8d9f-18e3a5a8641d 4f199347-ac43-4a35-a84c-37e1d0015ee3 2f887fbd-1b47-419e-869d-c0cc421a883e d44c77c4-08b0-4851-aa97-a1417aa3ddc4\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2f887fbd-1b47-419e-869d-c0cc421a883e'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/d44c77c4-08b0-4851-aa97-a1417aa3ddc4'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/4f199347-ac43-4a35-a84c-37e1d0015ee3'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/9e8258ee-d82a-4d69-8d9f-18e3a5a8641d'}, 'displayName': 'vi_eval_plain_vs_zip_Call19', 'description': 'evaluate the Vietnamese base model', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 2b438ab1-495b-4c02-a174-7969f866d29c\n"
     ]
    }
   ],
   "source": [
    "description = \"evaluate the Vietnamese base model\"\n",
    "locale = \"vi-VN\"\n",
    "evaluation_id={}\n",
    "for display_name in uploaded_files:\n",
    "    evaluation_id[display_name] = create_evaluation(base_url, headers, project_id, dataset_id[display_name], custom_model_with_plain_id, custom_model_with_zip_id, f'vi_eval_plain_vs_zip_{display_name}', description, locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_evaluation_status(evaluation_id):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = get_evaluation_status(base_url, headers, evaluation_id)\n",
    "        if status == \"NotStarted\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Succeeded\" and status != \"Failed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = get_evaluation_status(base_url, headers, evaluation_id)\n",
    "        while(pbar.n < 3):\n",
    "            pbar.update(1)\n",
    "        print(\"Evaluation Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███▎      | 1/3 [00:01<00:02,  1.02s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████▋   | 2/3 [01:18<00:45, 45.88s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [01:29<00:00, 29.85s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:01<00:00,  2.37step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:01<00:00,  2.40step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for display_name in uploaded_files:\n",
    "    monitor_evaluation_status(evaluation_id[display_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation_results(base_url, headers, evaluation_id):\n",
    "    \"\"\"\n",
    "    Prints the Word Error Rate (WER) and other evaluation metrics.\n",
    "    \"\"\"\n",
    "    evaluation_url = f'{base_url}/v3.2/evaluations/{evaluation_id}'\n",
    "    response = requests.get(evaluation_url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results for Call17 Call18 Call19 \n",
      "  Dataset    WER1    WER2\n",
      "0  Call17  0.1701  0.1633\n",
      "1  Call18  0.0775  0.0775\n",
      "2  Call19  0.1558  0.1658\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Collect WER results for each dataset\n",
    "wer_results = []\n",
    "eval_title = \"Evaluation Results for \"\n",
    "for display_name in uploaded_files:\n",
    "    eval_info = get_evaluation_results(base_url, headers, evaluation_id[display_name])\n",
    "    eval_title = eval_title + display_name + \" \"\n",
    "    wer_results.append({\n",
    "            'Dataset': display_name,\n",
    "            'WER1': eval_info['properties']['wordErrorRate1'],\n",
    "            'WER2': eval_info['properties']['wordErrorRate2'],\n",
    "            \n",
    "    })\n",
    "# Create a DataFrame to display the results\n",
    "wer_df = pd.DataFrame(wer_results)\n",
    "print(eval_title)\n",
    "print(wer_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
