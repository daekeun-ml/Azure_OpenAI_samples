{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Eval] Evaluate Trained Custom Speech Models\n",
    "This sample demonstrates how to evaluate Trained Custom Speech models calling REST API. \n",
    "\n",
    "> ✨ ***Note*** <br>\n",
    "> You can test the accuracy of your custom model by creating a test. A test requires a collection of audio files and their corresponding transcriptions. You can compare a custom model's accuracy with a speech to text base model or another custom model. After you get the test results, evaluate the word error rate (WER) compared to speech recognition results. \n",
    "\n",
    "## Prerequisites\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddd89716-eb27-4e95-868e-91588348a699 cc932fe1-f7a2-49d4-b8e8-c7c836d67297 2845aa88-8eca-4142-8035-e3393ad7f29c\n"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from utils.common import *\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "speech_key = os.getenv(\"AZURE_AI_SPEECH_API_KEY\")\n",
    "speech_region = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "\n",
    "# Get the project and custom model IDs from the previous notebook\n",
    "project_id = \"\"\n",
    "custom_model_with_plain_id = \"\"\n",
    "custom_model_with_acoustic_id = \"\"\n",
    "%store -r project_id\n",
    "%store -r custom_model_with_plain_id\n",
    "%store -r custom_model_with_acoustic_id\n",
    "\n",
    "try:\n",
    "    project_id, custom_model_with_plain_id, custom_model_with_acoustic_id\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the previous notebook again.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "print(project_id, custom_model_with_plain_id, custom_model_with_acoustic_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test based speech models\n",
    "- In order to learn how to quantitatively measure and improve the accuracy of the base speech to text model or your own custom models check this link\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-speech-evaluate-data?pivots=speech-cli#create-a-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the word error rate (WER) of a base model in Azure AI’s Speech service, follow these steps:\n",
    "\n",
    "Sign in to the Speech Studio:\n",
    "Go to the Azure Speech Studio.\n",
    "Create a Test:\n",
    "Navigate to Custom speech and select your project.\n",
    "Go to Test models and click on Create new test.\n",
    "Select Evaluate accuracy and click Next.\n",
    "Choose an audio + human-labeled transcription dataset. If you don’t have any datasets, upload them in the Speech datasets menu.\n",
    "Select up to two models to evaluate, then click Next.\n",
    "Enter the test name and description, then click Next.\n",
    "Review the test details and click Save and close.\n",
    "Get Test Results:\n",
    "After the test is complete, indicated by the status set to Succeeded, you will see the results, including the WER for each tested model.\n",
    "Evaluate WER:\n",
    "WER is calculated as the sum of insertion, deletion, and substitution errors divided by the total number of words in the reference transcript, multiplied by 100 to get a percentage1.\n",
    "For more detailed instructions, you can refer to this link - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-speech-evaluate-data?pivots=rest-api.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Base URL for the Speech Services REST API\n",
    "base_url = f'https://{speech_region}.api.cognitive.microsoft.com/speechtotext'\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': speech_key,\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the custom speech model ids to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model_id:  8066b5fb-0114-4837-90b6-0c245928a896\n",
      "custom_model_with_plain_id:  cc932fe1-f7a2-49d4-b8e8-c7c836d67297\n",
      "custom_model_with_acoustic_id:  2845aa88-8eca-4142-8035-e3393ad7f29c\n"
     ]
    }
   ],
   "source": [
    "# check the model id from the train a new model (UI) in the Azure Speech Studio. \n",
    "# The base model ids are vary from each language \n",
    "base_model_id = \"8066b5fb-0114-4837-90b6-0c245928a896\"  # Vietnamese base model id\n",
    "print(\"base_model_id: \", base_model_id)\n",
    "print(\"custom_model_with_plain_id: \", custom_model_with_plain_id)\n",
    "print(\"custom_model_with_acoustic_id: \", custom_model_with_acoustic_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload zip files to a storage account and generate content urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded successfully.\n",
      "uploaded_files: ['Call23', 'Call30', 'Call19', 'Call27', 'Call2', 'Call6', 'Call18', 'Call25', 'Call17']\n",
      "url: {'Call23': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call23.zip?se=2024-11-29T16%3A07%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=vWe6u%2BKhuAiq4H/yKys1tD22/E6X95Jcdy5Yr9fC07I%3D', 'Call30': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call30.zip?se=2024-11-29T16%3A07%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=bcFRynnbV/bbPkpULkEM60SxdDMZztIhdhRUEWB80Z0%3D', 'Call19': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call19.zip?se=2024-11-29T16%3A07%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=x7cxBH9tz%2ByajrweSTUl%2Bs3y6SjHOKjO2hmhxOWUbpU%3D', 'Call27': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call27.zip?se=2024-11-29T16%3A07%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=9yg5PstJH6anI6uD%2BJMiDTNLjmV39ZhOoY0bU4lMkFM%3D', 'Call2': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call2.zip?se=2024-11-29T16%3A07%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=KXtoSrCCJj/Os5WC8Q2lFrCkeA9LzCO8y3fbCDSAM4w%3D', 'Call6': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call6.zip?se=2024-11-29T16%3A07%3A50Z&sp=r&sv=2025-01-05&sr=b&sig=qtHlNJcMZYqw4iM8OIGSm39fIEHpG6V7q2FweY11QLQ%3D', 'Call18': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call18.zip?se=2024-11-29T16%3A07%3A50Z&sp=r&sv=2025-01-05&sr=b&sig=1smxu4AL60lgb1/%2Bc854koHjQQNW5vMOKV1hhc0SFa0%3D', 'Call25': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call25.zip?se=2024-11-29T16%3A07%3A50Z&sp=r&sv=2025-01-05&sr=b&sig=oSLAZwAyOakwLRgBFfTefTB5w3O%2BHFBqazt7rJOcaOA%3D', 'Call17': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/Call17.zip?se=2024-11-29T16%3A07%3A50Z&sp=r&sv=2025-01-05&sr=b&sig=UR0r6C5x2QbdK4B4Zk0bAN2be6Ewr8pL%2BvVob81NdQ8%3D'}\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, generate_blob_sas, BlobSasPermissions\n",
    "import os\n",
    "import datetime\n",
    "data_folder = \"eval_dataset\"\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_STORAGE_CONTAINER_NAME\")\n",
    "\n",
    "uploaded_files, url = upload_dataset_to_storage(data_folder, container_name, account_name, account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with ID: 4b398307-a1fb-4379-ad3c-a30690de4a43\n",
      "Dataset created with ID: 5c857663-0749-4111-bb98-ca45f8fbe18f\n",
      "Dataset created with ID: 52f09d11-668b-4953-a5c5-aa1b0bbaa7a9\n",
      "Dataset created with ID: 16b0f54f-777f-484b-88a8-4fedeb710835\n",
      "Dataset created with ID: f2240746-51ee-425e-bd90-21443595cf70\n",
      "Dataset created with ID: d9a69f06-3c6e-4b68-8983-dfa306c69baa\n",
      "Dataset created with ID: 1ca6619b-4603-49e0-8ab3-e4d867d74649\n",
      "Dataset created with ID: b28a138f-8ce1-464f-b5fd-10796ad3213f\n",
      "Dataset created with ID: 4b0d2071-f48d-4d15-a5ec-3a1f67424a70\n"
     ]
    }
   ],
   "source": [
    "kind=\"Acoustic\"\n",
    "description = \"Evaluation Dataset for Vietnamese Speech Recognition\"\n",
    "locale = \"vi-VN\"\n",
    "dataset_id = {}\n",
    "\n",
    "for display_name in uploaded_files:\n",
    "    dataset_id[display_name] = create_dataset(base_url, headers, project_id, url[display_name], kind, display_name, description, locale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of the trained Custom Speech model creating evaluations (tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "ddd89716-eb27-4e95-868e-91588348a699 4b398307-a1fb-4379-ad3c-a30690de4a43 8066b5fb-0114-4837-90b6-0c245928a896 2845aa88-8eca-4142-8035-e3393ad7f29c\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2845aa88-8eca-4142-8035-e3393ad7f29c'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/4b398307-a1fb-4379-ad3c-a30690de4a43'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}, 'displayName': 'vi_eval_base_vs_custom_Call23', 'description': 'evaluate the Vietnamese models', 'locale': 'vi-VN'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation job created with ID: 9d3f0664-c32f-474c-a9d9-72a692d398cb\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "ddd89716-eb27-4e95-868e-91588348a699 5c857663-0749-4111-bb98-ca45f8fbe18f 8066b5fb-0114-4837-90b6-0c245928a896 2845aa88-8eca-4142-8035-e3393ad7f29c\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2845aa88-8eca-4142-8035-e3393ad7f29c'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/5c857663-0749-4111-bb98-ca45f8fbe18f'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}, 'displayName': 'vi_eval_base_vs_custom_Call30', 'description': 'evaluate the Vietnamese models', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 27a41bd6-69cf-4855-ad9f-d924d96694dd\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "ddd89716-eb27-4e95-868e-91588348a699 52f09d11-668b-4953-a5c5-aa1b0bbaa7a9 8066b5fb-0114-4837-90b6-0c245928a896 2845aa88-8eca-4142-8035-e3393ad7f29c\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2845aa88-8eca-4142-8035-e3393ad7f29c'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/52f09d11-668b-4953-a5c5-aa1b0bbaa7a9'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}, 'displayName': 'vi_eval_base_vs_custom_Call19', 'description': 'evaluate the Vietnamese models', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 1327cffa-d43f-4a54-8592-9b6169965cc2\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "ddd89716-eb27-4e95-868e-91588348a699 16b0f54f-777f-484b-88a8-4fedeb710835 8066b5fb-0114-4837-90b6-0c245928a896 2845aa88-8eca-4142-8035-e3393ad7f29c\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2845aa88-8eca-4142-8035-e3393ad7f29c'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/16b0f54f-777f-484b-88a8-4fedeb710835'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}, 'displayName': 'vi_eval_base_vs_custom_Call27', 'description': 'evaluate the Vietnamese models', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 83801316-711d-40b6-bbee-83ea49bba7a2\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "ddd89716-eb27-4e95-868e-91588348a699 f2240746-51ee-425e-bd90-21443595cf70 8066b5fb-0114-4837-90b6-0c245928a896 2845aa88-8eca-4142-8035-e3393ad7f29c\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2845aa88-8eca-4142-8035-e3393ad7f29c'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/f2240746-51ee-425e-bd90-21443595cf70'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}, 'displayName': 'vi_eval_base_vs_custom_Call2', 'description': 'evaluate the Vietnamese models', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 14ec65c3-8f0b-4d36-b769-2698f9673c0a\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "ddd89716-eb27-4e95-868e-91588348a699 d9a69f06-3c6e-4b68-8983-dfa306c69baa 8066b5fb-0114-4837-90b6-0c245928a896 2845aa88-8eca-4142-8035-e3393ad7f29c\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2845aa88-8eca-4142-8035-e3393ad7f29c'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/d9a69f06-3c6e-4b68-8983-dfa306c69baa'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}, 'displayName': 'vi_eval_base_vs_custom_Call6', 'description': 'evaluate the Vietnamese models', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 7ca438d1-1477-4eb4-803b-d061508285c3\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "ddd89716-eb27-4e95-868e-91588348a699 1ca6619b-4603-49e0-8ab3-e4d867d74649 8066b5fb-0114-4837-90b6-0c245928a896 2845aa88-8eca-4142-8035-e3393ad7f29c\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2845aa88-8eca-4142-8035-e3393ad7f29c'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/1ca6619b-4603-49e0-8ab3-e4d867d74649'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}, 'displayName': 'vi_eval_base_vs_custom_Call18', 'description': 'evaluate the Vietnamese models', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 266abf81-0900-42b1-93eb-67f6e5ba29ec\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "ddd89716-eb27-4e95-868e-91588348a699 b28a138f-8ce1-464f-b5fd-10796ad3213f 8066b5fb-0114-4837-90b6-0c245928a896 2845aa88-8eca-4142-8035-e3393ad7f29c\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2845aa88-8eca-4142-8035-e3393ad7f29c'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/b28a138f-8ce1-464f-b5fd-10796ad3213f'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}, 'displayName': 'vi_eval_base_vs_custom_Call25', 'description': 'evaluate the Vietnamese models', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 3352973d-0605-41b6-84b2-ccfc4e0ee243\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/evaluations\n",
      "ddd89716-eb27-4e95-868e-91588348a699 4b0d2071-f48d-4d15-a5ec-3a1f67424a70 8066b5fb-0114-4837-90b6-0c245928a896 2845aa88-8eca-4142-8035-e3393ad7f29c\n",
      "{'model1': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/8066b5fb-0114-4837-90b6-0c245928a896'}, 'model2': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/2845aa88-8eca-4142-8035-e3393ad7f29c'}, 'dataset': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/4b0d2071-f48d-4d15-a5ec-3a1f67424a70'}, 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}, 'displayName': 'vi_eval_base_vs_custom_Call17', 'description': 'evaluate the Vietnamese models', 'locale': 'vi-VN'}\n",
      "Evaluation job created with ID: 07746c3f-3994-48da-8a4f-d1a1ecb262d7\n"
     ]
    }
   ],
   "source": [
    "description = \"evaluate the Vietnamese models\"\n",
    "locale = \"vi-VN\"\n",
    "evaluation_id={}\n",
    "for display_name in uploaded_files:\n",
    "    evaluation_id[display_name] = create_evaluation(base_url, headers, project_id, dataset_id[display_name], base_model_id, custom_model_with_acoustic_id, f'vi_eval_base_vs_custom_{display_name}', description, locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_evaluation_status(evaluation_id):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = get_evaluation_status(base_url, headers, evaluation_id)\n",
    "        if status == \"NotStarted\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Succeeded\" and status != \"Failed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = get_evaluation_status(base_url, headers, evaluation_id)\n",
    "        while(pbar.n < 3):\n",
    "            pbar.update(1)\n",
    "        print(\"Evaluation Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████▋   | 2/3 [01:30<00:45, 45.21s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [01:40<00:00, 33.49s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:00<00:00, 99.53step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:10<00:00,  3.36s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:10<00:00,  3.36s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:00<00:00, 69.08step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:00<00:00, 107.70step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:00<00:00, 102.66step/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:10<00:00,  3.35s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:00<00:00, 112.48step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for display_name in uploaded_files:\n",
    "    monitor_evaluation_status(evaluation_id[display_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results for base model and custom model: Call23 Call30 Call19 Call27 Call2 Call6 Call18 Call25 Call17 \n",
      "  Dataset  WER_base_model  WER_custom_model\n",
      "0  Call23          0.0805            0.0738\n",
      "1  Call30          0.0839            0.0872\n",
      "2  Call19          0.1457            0.1809\n",
      "3  Call27          0.1230            0.0802\n",
      "4   Call2          0.1375            0.1417\n",
      "5   Call6          0.1492            0.1694\n",
      "6  Call18          0.0702            0.0726\n",
      "7  Call25          0.2005            0.2137\n",
      "8  Call17          0.1905            0.1769\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Collect WER results for each dataset\n",
    "wer_results = []\n",
    "eval_title = \"Evaluation Results for base model and custom model: \"\n",
    "for display_name in uploaded_files:\n",
    "    eval_info = get_evaluation_results(base_url, headers, evaluation_id[display_name])\n",
    "    eval_title = eval_title + display_name + \" \"\n",
    "    wer_results.append({\n",
    "            'Dataset': display_name,\n",
    "            'WER_base_model': eval_info['properties']['wordErrorRate1'],\n",
    "            'WER_custom_model': eval_info['properties']['wordErrorRate2'],\n",
    "            \n",
    "    })\n",
    "# Create a DataFrame to display the results\n",
    "wer_df = pd.DataFrame(wer_results)\n",
    "print(eval_title)\n",
    "print(wer_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
