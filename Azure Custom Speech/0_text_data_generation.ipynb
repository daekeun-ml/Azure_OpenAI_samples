{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [text gen] Plain Text Generation with phi3.5\n",
    "This sample demonstrates how to generate a plain text file to train custom speech model. \n",
    "\n",
    "> âœ¨ ***Note*** <br>\n",
    "> Please check the custom speech support for each language before you get started - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#:~:text=Custom%20speech%20support \n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Git clone the repository to your local machine. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "* A subscription key for the Speech service. See [Try the speech service for free](https://docs.microsoft.com/azure/cognitive-services/speech-service/get-started).\n",
    "* Python 3.5 or later needs to be installed. Downloads are available [here](https://www.python.org/downloads/).\n",
    "* The Python Speech SDK package is available for Windows (x64 or x86) and Linux (x64; Ubuntu 16.04 or Ubuntu 18.04).\n",
    "* On Ubuntu 16.04 or 18.04, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install libssl3 libasound2\n",
    "  ```\n",
    "* On Debian 9, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install libssl1.0.2 libasound2\n",
    "  ```\n",
    "* On Windows you need the [Microsoft Visual C++ Redistributable for Visual Studio 2017](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads) for your platform.\n",
    "\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "```bash\n",
    "python3 -m venv your_env_name\n",
    "source your_env_name/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## 1. Generate synthetic dataset with phi3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage\n",
    "from azure.ai.inference.models import UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "SPEECH_KEY = os.getenv(\"AZURE_AI_SPEECH_API_KEY\")\n",
    "SPEECH_REGION = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "CUSTOM_SPEECH_LANG = os.getenv(\"CUSTOM_SPEECH_LANG\")\n",
    "CUSTOM_SPEECH_LOCALE = os.getenv(\"CUSTOM_SPEECH_LOCALE\")\n",
    "\n",
    "phi_api_endpoint = os.getenv(\"AZURE_PHI3.5_ENDPOINT\")\n",
    "phi_api_key = os.getenv(\"AZURE_PHI3.5_API_KEY\")\n",
    "phi_deployment_name = os.getenv(\"AZURE_PHI3.5_DEPLOYMENT_NAME\")\n",
    "\n",
    "try:\n",
    "    client = ChatCompletionsClient(\n",
    "    #endpoint=\"https://aoai-services1.services.ai.azure.com/models/chat/completions?api-version=2024-05-01-preview\", # you will run into a 500 error if you use this endpoint\n",
    "    endpoint=\"https://aoai-services1.services.ai.azure.com/models\",\n",
    "    credential=AzureKeyCredential(phi_api_key),\n",
    ")\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)\n",
    "\n",
    "phi_deployment_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare prompt to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference.models import SystemMessage\n",
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "topic = f\"\"\"\n",
    "LG electronics call center QnA related expected spoken utterances for {CUSTOM_SPEECH_LANG} and English languages.\n",
    "\"\"\"\n",
    "question = f\"\"\"\n",
    "create 10 lines of jsonl of the topic in {CUSTOM_SPEECH_LANG} and english. jsonl format is required. use 'no' as number and '{CUSTOM_SPEECH_LOCALE}', 'en-US' keys for the languages.\n",
    "only include the lines as the result. Do not include ```jsonl, ``` and blank line in the result. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(content=\"\"\"\n",
    "        Generate plain text sentences of #topic# related text to improve the recognition of domain-specific words and phrases.\n",
    "        Domain-specific words can be uncommon or made-up words, but their pronunciation must be straightforward to be recognized. \n",
    "        Use text data that's close to the expected spoken utterances. The nummber of utterances per line should be 1. \n",
    "        \"\"\"),\n",
    "\n",
    "       \n",
    "        UserMessage(content=f\"\"\"\n",
    "        #topic#: {topic}\n",
    "        Question: {question}\n",
    "        \"\"\"),\n",
    "    ],\n",
    "    # Simply change the model name for the appropiate model \"Phi-3.5-mini-instruct\" or \"Phi-3.5-vision-instruct\"\n",
    "    model=phi_deployment_name, \n",
    "    temperature=0.8,\n",
    "    max_tokens=2048,\n",
    "    top_p=0.1\n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "print(content)\n",
    "print(\"Usage Information:\")\n",
    "#print(f\"Cached Tokens: {response.usage.prompt_tokens_details.cached_tokens}\") #only o1 models support this\n",
    "print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Total Tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_text_file = \"cc_support_expressions.jsonl\"\n",
    "with open(synthetic_text_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(content)\n",
    "\n",
    "%store synthetic_text_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a plain text file to train custom speech models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "languages = [CUSTOM_SPEECH_LOCALE] # List of languages to generate audio files\n",
    "output_dir = \"plain_text\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "with open(synthetic_text_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            expression = json.loads(line)\n",
    "            for lang in languages:\n",
    "                text = expression[lang]\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                file_name = f\"{lang}_{timestamp}.txt\"\n",
    "                with open(os.path.join(output_dir,file_name), 'a', encoding='utf-8') as plain_text:\n",
    "                    plain_text.write(f\"{text}\\n\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON on line: {line}\")\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"plain_text\"  # Redefine output_dir if necessary\n",
    "\n",
    "with open(os.path.join(output_dir, file_name), 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the generated text file path in the variable `plain_text_path` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_text_path = os.path.join(output_dir, file_name)\n",
    "%store plain_text_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
