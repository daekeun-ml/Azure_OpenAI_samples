{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Speech to Text] Create Custom Speech Model for Vietnamese Language\n",
    "This sample demonstrates how to create Custom Speech model calling REST API. \n",
    "\n",
    "> ✨ ***Note*** <br>\n",
    "> Please check the custom speech support for each language before you get started - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#:~:text=Custom%20speech%20support \n",
    "\n",
    "## Prerequisites\n",
    "Git clone the repository to your local machine. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "* A subscription key for the Speech service. See [Try the speech service for free](https://docs.microsoft.com/azure/cognitive-services/speech-service/get-started).\n",
    "* Python 3.5 or later needs to be installed. Downloads are available [here](https://www.python.org/downloads/).\n",
    "* The Python Speech SDK package is available for Windows (x64 or x86) and Linux (x64; Ubuntu 16.04 or Ubuntu 18.04).\n",
    "* On Ubuntu 16.04 or 18.04, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install libssl1.0.0 libasound2\n",
    "  ```\n",
    "* On Debian 9, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install libssl1.0.2 libasound2\n",
    "  ```\n",
    "* On Windows you need the [Microsoft Visual C++ Redistributable for Visual Studio 2017](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads) for your platform.\n",
    "\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## 1. Test STT(Speech to Text) of Azure AI Speech by the synthetic dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataset\\\\train_vi-VN_20241110220748.zip'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from utils.common import *\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "speech_key = os.getenv(\"AZURE_AI_SPEECH_API_KEY\")\n",
    "speech_region = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "\n",
    "train_dataset_path = \"\"\n",
    "%store -r train_dataset_path\n",
    "try:\n",
    "    train_dataset_path\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the previous notebook again.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "train_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Base URL for the Speech Services REST API\n",
    "base_url = f'https://{speech_region}.api.cognitive.microsoft.com/speechtotext'\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': speech_key,\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognition_from_file(file_path: str, lang:str):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region, speech_recognition_language=lang)\n",
    "    audio_config = speechsdk.AudioConfig(filename=file_path)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "    return speech_recognition_result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the sorted wav files from the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_vi-VN_20241110220608.wav',\n",
       " '2_vi-VN_20241110220612.wav',\n",
       " '3_vi-VN_20241110220616.wav',\n",
       " '4_vi-VN_20241110220620.wav',\n",
       " '5_vi-VN_20241110220624.wav',\n",
       " '6_vi-VN_20241110220629.wav',\n",
       " '7_vi-VN_20241110220632.wav',\n",
       " '8_vi-VN_20241110220636.wav',\n",
       " '9_vi-VN_20241110220640.wav',\n",
       " '10_vi-VN_20241110220644.wav',\n",
       " '11_vi-VN_20241110220648.wav',\n",
       " '12_vi-VN_20241110220652.wav',\n",
       " '13_vi-VN_20241110220655.wav',\n",
       " '14_vi-VN_20241110220659.wav',\n",
       " '15_vi-VN_20241110220704.wav',\n",
       " '16_vi-VN_20241110220708.wav',\n",
       " '17_vi-VN_20241110220711.wav',\n",
       " '18_vi-VN_20241110220715.wav',\n",
       " '19_vi-VN_20241110220719.wav',\n",
       " '20_vi-VN_20241110220722.wav']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "output_folder = 'synthetic_data'\n",
    "files = os.listdir(output_folder)\n",
    "wav_files = [file for file in files if file.endswith('.wav')]\n",
    "\n",
    "# Sort wav_files by 'no' in ascending order\n",
    "wav_files.sort(key=lambda x: int(x.split('_')[0]))\n",
    "wav_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi có thể được trợ giúp bằng tiếng anh không?\n",
      "Máy giặt của tôi không hoạt động, tôi phải làm gì?\n",
      "Lg có chính sách bảo hành bao lâu?\n"
     ]
    }
   ],
   "source": [
    "for wav_file in wav_files[0:3]:\n",
    "    print(speech_recognition_from_file(os.path.join(output_folder,wav_file), \"vi-VN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload training datasets \n",
    "- You can upload datasets for training, qualitative inspection, and quantitative measurement. \n",
    "- This lab covers two types (Acoustic and Plain text) of training and testing data that you can use for custom speech. \n",
    "- Check the other options on this link - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-speech-test-and-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created with ID: 8b0eb25b-38f1-4f7b-8cfe-641753cd9cd1\n"
     ]
    }
   ],
   "source": [
    "display_name = \"My Custom Model Training And Evaluation Project\"\n",
    "description = \"Project for training and evaluating the Vietnamese base model\"\n",
    "locale = \"vi-VN\"\n",
    "project_id = create_project(base_url, headers, display_name, description, locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project_id' (str)\n"
     ]
    }
   ],
   "source": [
    "# Store the project_id for later use\n",
    "%store project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the acoustic dataset to storage (zip files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded successfully.\n",
      "uploaded_files: ['train_vi-VN_20241110220748']\n",
      "url: {'train_vi-VN_20241110220748': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/train_vi-VN_20241110220748.zip?se=2024-11-10T21%3A09%3A11Z&sp=r&sv=2024-11-04&sr=b&sig=UP3EYV%2BJ/1h4XrVy9rlTc0LCSEYwW4PQIu7RES/vhls%3D'}\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"train_dataset\"\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_STORAGE_CONTAINER_NAME\")\n",
    "\n",
    "uploaded_files, url = upload_dataset_to_storage(data_folder, container_name, account_name, account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets with the uploaded acoustic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with ID: 379fc89a-e577-466c-b34b-0eca564cdffb\n"
     ]
    }
   ],
   "source": [
    "kind=\"Acoustic\"\n",
    "display_name = \"acoustic dataset(zip) for training\"\n",
    "description = \"Dataset for training the Vietnamese base model\"\n",
    "locale = \"vi-VN\"\n",
    "\n",
    "zip_dataset_dict = {}\n",
    "\n",
    "for display_name in uploaded_files:\n",
    "    zip_dataset_dict[display_name] = create_dataset(base_url, headers, project_id, url[display_name], kind, display_name, description, locale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the plain text dataset to storage (text files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded successfully.\n",
      "uploaded_files: ['vi-VN_20241108095916', 'vi-VN_20241110220522']\n",
      "url: {'vi-VN_20241108095916': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/vi-VN_20241108095916.txt?se=2024-11-10T21%3A09%3A18Z&sp=r&sv=2024-11-04&sr=b&sig=2scFGsEA4pcxR2jsUVdH61LZ/Q95xAq1Nl2KRQyRnYw%3D', 'vi-VN_20241110220522': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/vi-VN_20241110220522.txt?se=2024-11-10T21%3A09%3A18Z&sp=r&sv=2024-11-04&sr=b&sig=bLoXwVzMzPq3k9onNnArTZesfpJwhkuPt/hOfVBlqbA%3D'}\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"plain_text\"\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_STORAGE_CONTAINER_NAME\")\n",
    "\n",
    "uploaded_files, url = upload_dataset_to_storage(data_folder, container_name, account_name, account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets with the uploaded plain text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with ID: 9b4d0d9d-2fbe-4f25-8a41-9ebc049aa6d9\n",
      "Dataset created with ID: c9023a6b-fd40-48b3-b40c-7f99a592d83f\n"
     ]
    }
   ],
   "source": [
    "kind=\"Language\"\n",
    "display_name = \"plain text dataset for training\"\n",
    "description = \"Dataset for training the Vietnamese base model\"\n",
    "locale = \"vi-VN\"\n",
    "\n",
    "plain_dataset_dict = {}\n",
    "\n",
    "for display_name in uploaded_files:\n",
    "    plain_dataset_dict[display_name] = create_dataset(base_url, headers, project_id, url[display_name], kind, display_name, description, locale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Custom Speech Models with the uploaded datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896',\n",
       " 'links': {'manifest': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896/manifest'},\n",
       " 'properties': {'deprecationDates': {'adaptationDateTime': '2025-01-15T00:00:00Z',\n",
       "   'transcriptionDateTime': '2025-04-15T00:00:00Z'},\n",
       "  'features': {'supportsTranscriptions': True,\n",
       "   'supportsEndpoints': True,\n",
       "   'supportsTranscriptionsOnSpeechContainers': False,\n",
       "   'supportsAdaptationsWith': ['Language'],\n",
       "   'supportedOutputFormats': ['Display', 'Lexical']},\n",
       "  'chargeForAdaptation': False},\n",
       " 'lastActionDateTime': '2023-01-31T13:08:53Z',\n",
       " 'status': 'Succeeded',\n",
       " 'createdDateTime': '2023-01-31T12:16:46Z',\n",
       " 'locale': 'vi-VN',\n",
       " 'displayName': '20230111',\n",
       " 'description': 'vi-VN base model'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the model id from the train a new model (UI) in the Azure Speech Studio. \n",
    "# The base model ids are vary from each language \n",
    "base_model_id = \"8066b5fb-0114-4837-90b6-0c245928a896\"  # Vietnamese base model id\n",
    "base_model = get_base_model(base_url, headers, base_model_id)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the custom speech model with plain text datasets (txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'displayName': 'vi_custom_model_with_plain_text', 'description': 'Custom model training with plain text dataset', 'locale': 'vi-VN', 'baseModel': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896'}, 'datasets': [{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/9b4d0d9d-2fbe-4f25-8a41-9ebc049aa6d9'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/c9023a6b-fd40-48b3-b40c-7f99a592d83f'}], 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/8b0eb25b-38f1-4f7b-8cfe-641753cd9cd1'}}\n",
      "custom model job created with ID: 762281d5-7387-45cf-8a1b-13f2670b15f3\n"
     ]
    }
   ],
   "source": [
    "display_name = \"vi_custom_model_with_plain_text\"\n",
    "description = \"Custom model training with plain text dataset\"\n",
    "locale = \"vi-VN\"\n",
    "custom_model_with_plain_id = create_custom_model(base_url, headers, project_id, base_model_id, list(plain_dataset_dict.values()), display_name, description, locale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the custom speech model with acoustic datasets (zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'displayName': 'vi_custom_model_with_aocustic_dataset', 'description': 'Custom model training with acoustic dataset', 'locale': 'vi-VN', 'baseModel': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896'}, 'datasets': [{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/379fc89a-e577-466c-b34b-0eca564cdffb'}], 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/8b0eb25b-38f1-4f7b-8cfe-641753cd9cd1'}}\n",
      "custom model job created with ID: 84bebf4d-b198-437f-bef5-619ee288bb36\n"
     ]
    }
   ],
   "source": [
    "display_name = \"vi_custom_model_with_aocustic_dataset\"\n",
    "description = \"Custom model training with acoustic dataset\"\n",
    "locale = \"vi-VN\"\n",
    "custom_model_with_acoustic_id = create_custom_model(base_url, headers, project_id, base_model_id, list(zip_dataset_dict.values()), display_name, description, locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_training_status(custom_model_id):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = get_custom_model_status(base_url, headers, custom_model_id)\n",
    "        if status == \"NotStarted\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Succeeded\" and status != \"Failed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = get_custom_model_status(base_url, headers, custom_model_id)\n",
    "        while(pbar.n < 3):\n",
    "            pbar.update(1)\n",
    "        print(\"Evaluation Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monitor training status for each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███▎      | 1/3 [00:01<00:02,  1.03s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████▋   | 2/3 [00:12<00:06,  6.91s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n",
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:34<00:00, 11.37s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:01<00:00,  2.96step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_training_status(custom_model_with_plain_id)\n",
    "monitor_training_status(custom_model_with_acoustic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'custom_model_with_plain_id' (str)\n",
      "Stored 'custom_model_with_zip_id' (str)\n"
     ]
    }
   ],
   "source": [
    "%store custom_model_with_plain_id\n",
    "%store custom_model_with_zip_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
