{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Speech to Text] Create Custom Speech Model for Vietnamese Language\n",
    "This sample demonstrates how to create Custom Speech model calling REST API. \n",
    "\n",
    "> ✨ ***Note*** <br>\n",
    "> Please check the custom speech support for each language before you get started - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#:~:text=Custom%20speech%20support \n",
    "\n",
    "## Prerequisites\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## 1. Test STT(Speech to Text) of Azure AI Speech by the synthetic dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataset/train_vi-VN_20241129075917.zip'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from utils.common import *\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "speech_key = os.getenv(\"AZURE_AI_SPEECH_API_KEY\")\n",
    "speech_region = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "\n",
    "train_dataset_path = \"\"\n",
    "%store -r train_dataset_path\n",
    "try:\n",
    "    train_dataset_path\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the previous notebook again.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "train_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Base URL for the Speech Services REST API\n",
    "base_url = f'https://{speech_region}.api.cognitive.microsoft.com/speechtotext'\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': speech_key,\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognition_from_file(file_path: str, lang:str):\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=speech_region, speech_recognition_language=lang)\n",
    "    audio_config = speechsdk.AudioConfig(filename=file_path)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "    return speech_recognition_result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the sorted wav files from the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_vi-VN_20241129075815.wav',\n",
       " '2_vi-VN_20241129075815.wav',\n",
       " '3_vi-VN_20241129075816.wav',\n",
       " '4_vi-VN_20241129075816.wav',\n",
       " '5_vi-VN_20241129075816.wav',\n",
       " '6_vi-VN_20241129075817.wav',\n",
       " '7_vi-VN_20241129075817.wav',\n",
       " '8_vi-VN_20241129075817.wav',\n",
       " '9_vi-VN_20241129075818.wav',\n",
       " '10_vi-VN_20241129075818.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "output_folder = 'synthetic_data'\n",
    "files = os.listdir(output_folder)\n",
    "wav_files = [file for file in files if file.endswith('.wav')]\n",
    "\n",
    "# Sort wav_files by 'no' in ascending order\n",
    "wav_files.sort(key=lambda x: int(x.split('_')[0]))\n",
    "wav_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chào bộ phận chăm sóc khách hàng RJ, tôi muốn hỏi về sản phẩm của công ty.\n",
      "Tôi gặp vấn đề với máy giặt lg, có thể bạn giúp tôi khắc phục không?\n",
      "Làm thế nào để tôi tắt chế độ chạy tự động trên máy giặt lg?\n"
     ]
    }
   ],
   "source": [
    "for wav_file in wav_files[0:3]:\n",
    "    print(speech_recognition_from_file(os.path.join(output_folder,wav_file), \"vi-VN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload training datasets \n",
    "- You can upload datasets for training, qualitative inspection, and quantitative measurement. \n",
    "- This lab covers two types (Acoustic and Plain text) of training and testing data that you can use for custom speech. \n",
    "- Check the other options on this link - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-speech-test-and-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created with ID: ddd89716-eb27-4e95-868e-91588348a699\n"
     ]
    }
   ],
   "source": [
    "display_name = \"My Custom Model Training And Evaluation Project\"\n",
    "description = \"Project for training and evaluating the Vietnamese base model\"\n",
    "locale = \"vi-VN\"\n",
    "project_id = create_project(base_url, headers, display_name, description, locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project_id' (str)\n"
     ]
    }
   ],
   "source": [
    "# Store the project_id for later use\n",
    "%store project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the acoustic dataset to storage (zip files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded successfully.\n",
      "uploaded_files: ['4-HD', '3-HD', '7-HD', 'train_vi-VN_20241111152003', '5-HY', '6-HD', 'train_vi-VN_20241129075917', '2-HY', '2-HD', '6-KA', '7-KA', '8-HD', '9-HD', '8-KA', '4-HY', '5-HD', '3-HY', '9-KA', '1-HY', '1-HD']\n",
      "url: {'4-HD': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/4-HD.zip?se=2024-11-29T16%3A02%3A48Z&sp=r&sv=2025-01-05&sr=b&sig=CZ9pHu8ikbSyufIfNBrygBHzfEeifa3qo1dJmf0WWnQ%3D', '3-HD': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/3-HD.zip?se=2024-11-29T16%3A02%3A48Z&sp=r&sv=2025-01-05&sr=b&sig=AMt5hqyDAo9VuAqj9BEfKnMwOQaXhtKbdx/smZ0WJ88%3D', '7-HD': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/7-HD.zip?se=2024-11-29T16%3A02%3A48Z&sp=r&sv=2025-01-05&sr=b&sig=v4w%2B8uLEFeH/zizQ2m7yCdrFtlmo38QZW5tTCKbJncQ%3D', 'train_vi-VN_20241111152003': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/train_vi-VN_20241111152003.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=PWPR2NMze4%2B2qVymTbDkhultfQXcukLBeLOzmfs/6tY%3D', '5-HY': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/5-HY.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=PsZ0jYabihyjofq8uV0wxkfDG0UbPQkEdbyvC/6yPvg%3D', '6-HD': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/6-HD.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=1484vfkVD6xl%2Bw1Qxt9plHq5ePKxP4%2B6n1dvdiSYjyA%3D', 'train_vi-VN_20241129075917': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/train_vi-VN_20241129075917.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=o%2BPJPxE9K%2BfWgsROeljFHhA0aXVBSlLRRVV3OohvrKs%3D', '2-HY': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/2-HY.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=ZpASGT6iy5hmrMYp2mZc804dx8Sv6wPXxEaVXoiypok%3D', '2-HD': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/2-HD.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=Lmx9nye4hXFjiD3O1LcbX0YpOt2TPoMRHo9heptWFaI%3D', '6-KA': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/6-KA.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=D7cF6yE0CiG91sIzHmp86Hc56QCEQJcPvA/AhRMzo6o%3D', '7-KA': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/7-KA.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=upsr5mEx1IEmz42NiLUptrIPhbA04frNGbLPft5MCKc%3D', '8-HD': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/8-HD.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=yJ8bEVP%2B4xdpaRfqQ8q9uvGH2BBOh9i6rs1tEn54CMA%3D', '9-HD': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/9-HD.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=V3XpL6K5114tUrnqz6wABtOfAPpfSrXwHV98zwP8uvY%3D', '8-KA': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/8-KA.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=9djHfkt7oXvDyiyzDqryUkoP/cMDon2/EeY9ygiSFQQ%3D', '4-HY': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/4-HY.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=mK8SqxIOMmAKKRISGqPdBBTYS2sbTyAspgHKh%2B6l9qo%3D', '5-HD': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/5-HD.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=LmzfSwO%2BoMH5rpoUS/oVpnLezTf/Utf7KjsszNY9isk%3D', '3-HY': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/3-HY.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=ISMItMIsadRoj6Su4apWBLpwIEZW3gCb2UhyzFr5Kiw%3D', '9-KA': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/9-KA.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=X35B3fcXxd4J/Ts8nstPqz2GD/lqGO0kYxodX7a67cg%3D', '1-HY': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/1-HY.zip?se=2024-11-29T16%3A02%3A49Z&sp=r&sv=2025-01-05&sr=b&sig=%2BTyhbQiTWpOlKq7zKOxfxJ///Hg423ZyiVpQQdnXMYg%3D', '1-HD': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/1-HD.zip?se=2024-11-29T16%3A02%3A50Z&sp=r&sv=2025-01-05&sr=b&sig=JFBLATzYZarK2/5UR%2B1SkQdlRc9T/iD/yQtqeeqaslg%3D'}\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"train_dataset\"\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_STORAGE_CONTAINER_NAME\")\n",
    "\n",
    "uploaded_files, url = upload_dataset_to_storage(data_folder, container_name, account_name, account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets with the uploaded acoustic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with ID: adc1a790-9a33-4ec1-96db-fa8be194d5fe\n",
      "Dataset created with ID: 6410655d-2d52-4f01-b281-fa3e35329493\n",
      "Dataset created with ID: 40c292f6-6722-42d1-8d64-c0d5dbb68583\n",
      "Dataset created with ID: 66b8215c-1044-4d13-b92c-ae1137298b0d\n",
      "Dataset created with ID: f399f516-90d3-4656-b2ca-312a0d451056\n",
      "Dataset created with ID: ada37ee3-5b0e-4dd6-a33d-7bfd137d0a11\n",
      "Dataset created with ID: 72f422b1-7f0d-46b0-836c-9d980c296edc\n",
      "Dataset created with ID: b054b3a9-0972-4996-89d4-84a02d9a4df1\n",
      "Dataset created with ID: a9835575-ab58-4c4b-91df-e16166fb1028\n",
      "Dataset created with ID: 43b7e8fc-0399-4404-a7fd-e0a834d1dc29\n",
      "Dataset created with ID: 03f02dbf-c899-4cce-a90c-fb589f73a692\n",
      "Dataset created with ID: cc2aa145-2152-4259-8680-d97a32d3fc78\n",
      "Dataset created with ID: 2deaadab-52e4-42e2-aa36-37550b4ff663\n",
      "Dataset created with ID: 691eb575-db84-4f5c-b93c-9da8fd894f0c\n",
      "Dataset created with ID: 0045e41b-7016-4dc3-a26d-20b838aea3f0\n",
      "Dataset created with ID: 9a5f2f05-a532-492f-b79b-6e4aa0ef7067\n",
      "Dataset created with ID: c1752c4a-b7e0-444d-a885-cdcdbc9735a6\n",
      "Dataset created with ID: d56b246b-6574-4351-aaaa-d9a6f241213b\n",
      "Dataset created with ID: b1dee042-ea1b-4947-8aa7-fac1c989bc48\n",
      "Dataset created with ID: f5d01c58-7871-486b-8f88-9d1575194060\n"
     ]
    }
   ],
   "source": [
    "kind=\"Acoustic\"\n",
    "display_name = \"acoustic dataset(zip) for training\"\n",
    "description = \"Dataset for training the Vietnamese base model\"\n",
    "locale = \"vi-VN\"\n",
    "\n",
    "zip_dataset_dict = {}\n",
    "\n",
    "for display_name in uploaded_files:\n",
    "    zip_dataset_dict[display_name] = create_dataset(base_url, headers, project_id, url[display_name], kind, display_name, description, locale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the plain text dataset to storage (text files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files uploaded successfully.\n",
      "uploaded_files: ['vi-VN_20241129075732']\n",
      "url: {'vi-VN_20241129075732': 'https://aoaihub1storageaccount.blob.core.windows.net/stt-container/vi-VN_20241129075732.txt?se=2024-11-29T16%3A02%3A57Z&sp=r&sv=2025-01-05&sr=b&sig=NJiR8wPcUyZ6130%2B8IS8OjTdFFciGo0sxEPB2/9xFvo%3D'}\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"plain_text\"\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_STORAGE_CONTAINER_NAME\")\n",
    "\n",
    "uploaded_files, url = upload_dataset_to_storage(data_folder, container_name, account_name, account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets with the uploaded plain text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with ID: 035d7e26-7698-40a3-aeee-8f692fd73be0\n"
     ]
    }
   ],
   "source": [
    "kind=\"Language\"\n",
    "display_name = \"plain text dataset for training\"\n",
    "description = \"Dataset for training the Vietnamese base model\"\n",
    "locale = \"vi-VN\"\n",
    "\n",
    "plain_dataset_dict = {}\n",
    "\n",
    "for display_name in uploaded_files:\n",
    "    plain_dataset_dict[display_name] = create_dataset(base_url, headers, project_id, url[display_name], kind, display_name, description, locale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Custom Speech Models with the uploaded datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ✨ ***Note*** <br>\n",
    "> Please check which version of base model support for adaptation from baseline model information <br>\n",
    "> for example, Italian language model 20230111, 2e5e70f1-960b-4509-a7c5-102b29227c0b supports 'Language', 'LanguageMarkdown', 'Pronunciation', 'OutputFormatting' adaptation.<br>\n",
    "> check the supportsAdaptationsWith feature of the base_model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896',\n",
       " 'links': {'manifest': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896/manifest'},\n",
       " 'properties': {'deprecationDates': {'adaptationDateTime': '2025-01-15T00:00:00Z',\n",
       "   'transcriptionDateTime': '2025-04-15T00:00:00Z'},\n",
       "  'features': {'supportsTranscriptions': True,\n",
       "   'supportsEndpoints': True,\n",
       "   'supportsTranscriptionsOnSpeechContainers': False,\n",
       "   'supportsAdaptationsWith': ['Language'],\n",
       "   'supportedOutputFormats': ['Display', 'Lexical']},\n",
       "  'chargeForAdaptation': False},\n",
       " 'lastActionDateTime': '2023-01-31T13:08:53Z',\n",
       " 'status': 'Succeeded',\n",
       " 'createdDateTime': '2023-01-31T12:16:46Z',\n",
       " 'locale': 'vi-VN',\n",
       " 'displayName': '20230111',\n",
       " 'description': 'vi-VN base model'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the model id from the train a new model (UI) in the Azure Speech Studio. \n",
    "# The base model ids are vary from each language \n",
    "base_model_id = \"8066b5fb-0114-4837-90b6-0c245928a896\"  # Vietnamese base model id\n",
    "base_model = get_base_model(base_url, headers, base_model_id)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the custom speech model with plain text datasets (txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'displayName': 'vi_custom_model_with_plain_text', 'description': 'Custom model training with plain text dataset', 'locale': 'vi-VN', 'baseModel': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896'}, 'datasets': [{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/035d7e26-7698-40a3-aeee-8f692fd73be0'}], 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom model job created with ID: cc932fe1-f7a2-49d4-b8e8-c7c836d67297\n"
     ]
    }
   ],
   "source": [
    "display_name = \"vi_custom_model_with_plain_text\"\n",
    "description = \"Custom model training with plain text dataset\"\n",
    "locale = \"vi-VN\"\n",
    "custom_model_with_plain_id = create_custom_model(base_url, headers, project_id, base_model_id, list(plain_dataset_dict.values()), display_name, description, locale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the custom speech model with acoustic datasets (zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'displayName': 'vi_custom_model_with_aocustic_dataset', 'description': 'Custom model training with acoustic dataset', 'locale': 'vi-VN', 'baseModel': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/models/base/8066b5fb-0114-4837-90b6-0c245928a896'}, 'datasets': [{'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/adc1a790-9a33-4ec1-96db-fa8be194d5fe'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/6410655d-2d52-4f01-b281-fa3e35329493'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/40c292f6-6722-42d1-8d64-c0d5dbb68583'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/66b8215c-1044-4d13-b92c-ae1137298b0d'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/f399f516-90d3-4656-b2ca-312a0d451056'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/ada37ee3-5b0e-4dd6-a33d-7bfd137d0a11'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/72f422b1-7f0d-46b0-836c-9d980c296edc'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/b054b3a9-0972-4996-89d4-84a02d9a4df1'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/a9835575-ab58-4c4b-91df-e16166fb1028'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/43b7e8fc-0399-4404-a7fd-e0a834d1dc29'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/03f02dbf-c899-4cce-a90c-fb589f73a692'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/cc2aa145-2152-4259-8680-d97a32d3fc78'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/2deaadab-52e4-42e2-aa36-37550b4ff663'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/691eb575-db84-4f5c-b93c-9da8fd894f0c'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/0045e41b-7016-4dc3-a26d-20b838aea3f0'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/9a5f2f05-a532-492f-b79b-6e4aa0ef7067'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/c1752c4a-b7e0-444d-a885-cdcdbc9735a6'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/d56b246b-6574-4351-aaaa-d9a6f241213b'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/b1dee042-ea1b-4947-8aa7-fac1c989bc48'}, {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/datasets/f5d01c58-7871-486b-8f88-9d1575194060'}], 'project': {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.2/projects/ddd89716-eb27-4e95-868e-91588348a699'}}\n",
      "custom model job created with ID: 2845aa88-8eca-4142-8035-e3393ad7f29c\n"
     ]
    }
   ],
   "source": [
    "display_name = \"vi_custom_model_with_aocustic_dataset\"\n",
    "description = \"Custom model training with acoustic dataset\"\n",
    "locale = \"vi-VN\"\n",
    "custom_model_with_acoustic_id = create_custom_model(base_url, headers, project_id, base_model_id, list(zip_dataset_dict.values()), display_name, description, locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_training_status(custom_model_id):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = get_custom_model_status(base_url, headers, custom_model_id)\n",
    "        if status == \"NotStarted\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Succeeded\" and status != \"Failed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = get_custom_model_status(base_url, headers, custom_model_id)\n",
    "        while(pbar.n < 3):\n",
    "            pbar.update(1)\n",
    "        print(\"Training Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### monitor training status for each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████▋   | 2/3 [00:10<00:05,  5.05s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:40<00:00, 13.41s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████| 3/3 [00:00<00:00, 100.03step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_training_status(custom_model_with_plain_id)\n",
    "monitor_training_status(custom_model_with_acoustic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'custom_model_with_plain_id' (str)\n",
      "Stored 'custom_model_with_acoustic_id' (str)\n"
     ]
    }
   ],
   "source": [
    "%store custom_model_with_plain_id\n",
    "%store custom_model_with_acoustic_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
