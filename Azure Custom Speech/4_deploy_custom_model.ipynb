{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Deploy and Run] Dploy the Trained Custom Speech Models\n",
    "This sample demonstrates how to deploy and run the trained Custom Speech models calling REST API. \n",
    "\n",
    "> âœ¨ ***Note*** <br>\n",
    "> Except for batch transcription, you must deploy a custom endpoint to use a custom speech model. You can deploy an endpoint for a base or custom model, and then update the endpoint later to use a better trained model. Endpoints used by F0 Speech resources are deleted after seven days.\n",
    "\n",
    "## Prerequisites\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from utils.common import *\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SPEECH_KEY = os.getenv(\"AZURE_AI_SPEECH_API_KEY\")\n",
    "SPEECH_REGION = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "CUSTOM_SPEECH_LANG = os.getenv(\"CUSTOM_SPEECH_LANG\")\n",
    "CUSTOM_SPEECH_LOCALE = os.getenv(\"CUSTOM_SPEECH_LOCALE\")\n",
    "\n",
    "# Get the project and custom model IDs from the previous notebook\n",
    "project_id = \"\"\n",
    "custom_model_with_plain_id = \"\"\n",
    "custom_model_with_acoustic_id = \"\"\n",
    "%store -r project_id\n",
    "%store -r custom_model_with_plain_id\n",
    "%store -r custom_model_with_acoustic_id\n",
    "\n",
    "try:\n",
    "    project_id, custom_model_with_plain_id, custom_model_with_acoustic_id\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the previous notebook again.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "print(project_id, custom_model_with_plain_id, custom_model_with_acoustic_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Deploy a trained speech model\n",
    "- In order to get more information about deploying the custom models, check this document link below\n",
    "- https://learn.microsoft.com/en-us/azure/ai-services/speech-service/how-to-custom-speech-deploy-model?pivots=rest-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Base URL for the Speech Services REST API\n",
    "base_url = f'https://{SPEECH_REGION}.api.cognitive.microsoft.com/speechtotext'\n",
    "\n",
    "# Headers for authentication\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': SPEECH_KEY,\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the custom speech model ids to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the custom model id to evaluate\n",
    "print(custom_model_with_plain_id, custom_model_with_acoustic_id)\n",
    "\n",
    "# Set the model id to deploy\n",
    "deploy_model_id = custom_model_with_acoustic_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an endpoint to deploy the custom speech model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_name = f\"[{CUSTOM_SPEECH_LANG}] My custom model deployment\"\n",
    "description = \"Custom model endpoint to deloy\"\n",
    "logging_enabled = True\n",
    "endpoint_id = create_endpoint(base_url, headers, project_id, deploy_model_id, display_name, description, CUSTOM_SPEECH_LOCALE, logging_enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_endpoint_status(endpoint_id):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = get_endpoint_status(base_url, headers, endpoint_id)\n",
    "        if status == \"NotStarted\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Succeeded\" and status != \"Failed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = get_endpoint_status(base_url, headers, endpoint_id)\n",
    "        while(pbar.n < 3):\n",
    "            pbar.update(1)\n",
    "        print(\"Endpoint Creation Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_endpoint_status(endpoint_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test the deployed custom model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test your deployed custom model by Python SDK. In order to set the endpoint, you need to get the endpoint id from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognition_from_file_with_endpoint(file_path: str, lang:str, endoint_id: str):\n",
    "    # Check the Parameters - https://learn.microsoft.com/en-us/python/api/azure-cognitiveservices-speech/azure.cognitiveservices.speech.speechconfig?view=azure-python\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION, speech_recognition_language=lang)\n",
    "    speech_config.endpoint_id = endoint_id\n",
    "    audio_config = speechsdk.AudioConfig(filename=file_path)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    speech_recognition_result = speech_recognizer.recognize_once_async().get()\n",
    "    return speech_recognition_result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the sorted wav files from the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "output_folder = 'synthetic_eval_data'\n",
    "files = os.listdir(output_folder)\n",
    "wav_files = [file for file in files if file.endswith('.wav')]\n",
    "\n",
    "# Sort wav_files by 'no' in ascending order\n",
    "wav_files.sort(key=lambda x: int(x.split('_')[0]))\n",
    "wav_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wav_file in wav_files[0:3]:\n",
    "    print(speech_recognition_from_file_with_endpoint(os.path.join(output_folder,wav_file), CUSTOM_SPEECH_LOCALE, endpoint_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Delete the all resources after testing\n",
    "- Don't forget to delete the deployed custom model and project after testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_endpoint(base_url, headers, endpoint_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_project(base_url, headers, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
