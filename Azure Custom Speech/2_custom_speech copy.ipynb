{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [TTS] Create Custom Speech Model \n",
    "This sample demonstrates how to create Custom Speech model calling REST API. \n",
    "\n",
    "> âœ¨ ***Note*** <br>\n",
    "> Please check the custom speech support for each language before you get started - https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=stt#:~:text=Custom%20speech%20support \n",
    "\n",
    "## Prerequisites\n",
    "Git clone the repository to your local machine. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "* A subscription key for the Speech service. See [Try the speech service for free](https://docs.microsoft.com/azure/cognitive-services/speech-service/get-started).\n",
    "* Python 3.5 or later needs to be installed. Downloads are available [here](https://www.python.org/downloads/).\n",
    "* The Python Speech SDK package is available for Windows (x64 or x86) and Linux (x64; Ubuntu 16.04 or Ubuntu 18.04).\n",
    "* On Ubuntu 16.04 or 18.04, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install libssl1.0.0 libasound2\n",
    "  ```\n",
    "* On Debian 9, run the following commands for the installation of required packages:\n",
    "  ```sh\n",
    "  sudo apt-get update\n",
    "  sudo apt-get install libssl1.0.2 libasound2\n",
    "  ```\n",
    "* On Windows you need the [Microsoft Visual C++ Redistributable for Visual Studio 2017](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads) for your platform.\n",
    "\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "speech_key = os.getenv(\"AZURE_AI_SPEECH_API_KEY\")\n",
    "speech_region = os.getenv(\"AZURE_AI_SPEECH_REGION\")\n",
    "\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': speech_key,\n",
    "    'Content-Type': 'application/json'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a Project\n",
    "def create_project(name, description, locale):\n",
    "    project_url = f\"https://{speech_region}.api.cognitive.microsoft.com/speechtotext/v3.1/projects\"\n",
    "    data = {\n",
    "        \"displayName\": name,\n",
    "        \"locale\": locale,\n",
    "        \"description\": description\n",
    "    }\n",
    "    response = requests.post(project_url, headers=headers, json=data)\n",
    "    if response.status_code == 201:\n",
    "        project = response.json()\n",
    "        print(f\"Project created : {project}\")\n",
    "        return project[\"self\"]\n",
    "    else:\n",
    "        print(f\"Failed to create project. Status code: {response.status_code}\")\n",
    "        print(\"Error message:\", response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project created : {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/projects/013d27fb-ae20-474f-b53c-cf9be14a007a', 'links': {'evaluations': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/projects/013d27fb-ae20-474f-b53c-cf9be14a007a/evaluations', 'datasets': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/projects/013d27fb-ae20-474f-b53c-cf9be14a007a/datasets', 'models': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/projects/013d27fb-ae20-474f-b53c-cf9be14a007a/models', 'endpoints': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/projects/013d27fb-ae20-474f-b53c-cf9be14a007a/endpoints', 'transcriptions': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/projects/013d27fb-ae20-474f-b53c-cf9be14a007a/transcriptions'}, 'properties': {'datasetCount': 0, 'evaluationCount': 0, 'modelCount': 0, 'transcriptionCount': 0, 'endpointCount': 0}, 'createdDateTime': '2024-11-04T10:02:31Z', 'locale': 'en-US', 'displayName': 'MyProject1', 'description': 'Project for custom speech model1'}\n",
      "https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/projects/013d27fb-ae20-474f-b53c-cf9be14a007a\n"
     ]
    }
   ],
   "source": [
    "project = create_project(\"MyProject1\", \"Project for custom speech model1\", \"en-US\")\n",
    "print(project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create an Acoustic Dataset\n",
    "def create_dataset(project, name, description, locale):\n",
    "    dataset_url = f\"https://{speech_region}.api.cognitive.microsoft.com/speechtotext/v3.1/datasets/upload\"\n",
    "    data = {\n",
    "        \"kind\": \"Acoustic\",\n",
    "        \"locale\": locale,\n",
    "        \"displayName\": name,\n",
    "        \"description\": description, \n",
    "        \"project\": project,\n",
    "        \"data\": {\n",
    "            \"contentUrls\": [\n",
    "                \"https://speechsamples.blob.core.windows.net/speech/short-audio.wav\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    response = requests.post(dataset_url, headers=headers, json=data)\n",
    "    if response.status_code == 201:\n",
    "        dataset = response.json()\n",
    "        print(f\"dataset created : {dataset}\")\n",
    "        return dataset['self']\n",
    "    else:\n",
    "        print(f\"Failed to create dataset. Status code: {response.status_code}\")\n",
    "        print(\"Error message:\", response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset created : {'self': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/datasets/6b6f2403-9cb0-4c43-9620-c8a4d92289ff', 'kind': 'Acoustic', 'links': {'files': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/datasets/6b6f2403-9cb0-4c43-9620-c8a4d92289ff/files', 'commitBlocks': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/datasets/6b6f2403-9cb0-4c43-9620-c8a4d92289ff/blocks:commit', 'listBlocks': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/datasets/6b6f2403-9cb0-4c43-9620-c8a4d92289ff/blocks', 'uploadBlocks': 'https://swedencentral.api.cognitive.microsoft.com/speechtotext/v3.1/datasets/6b6f2403-9cb0-4c43-9620-c8a4d92289ff/blocks'}, 'properties': {'acceptedLineCount': 0, 'rejectedLineCount': 0}, 'lastActionDateTime': '2024-11-04T10:14:16Z', 'status': 'NotStarted', 'createdDateTime': '2024-11-04T10:14:16Z', 'locale': 'en-US', 'displayName': 'MyDataset', 'description': 'Dataset for custom speech model'}\n"
     ]
    }
   ],
   "source": [
    "if(project):\n",
    "    dataset = create_dataset(project, \"MyDataset\", \"Dataset for custom speech model\", \"en-US\")\n",
    "print(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files_to_dataset(dataset_id, file_path):\n",
    "    upload_url = f\"https://{speech_region}.api.cognitive.microsoft.com/speechtotext/v3.1/datasets/{dataset_id}/files\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    params = {\n",
    "        \"fileName\": file_name\n",
    "    }\n",
    "    files = {\n",
    "        'data': (file_name, open(file_path, 'rb'), 'audio/wav')\n",
    "    }\n",
    "    response = requests.post(upload_url, headers={'Ocp-Apim-Subscription-Key': subscription_key}, params=params, files=files)\n",
    "    if response.status_code == 202:\n",
    "        print(f\"File '{file_name}' uploaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to upload file '{file_name}'. Status code: {response.status_code}\")\n",
    "        print(\"Error message:\", response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "askvoice-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
