{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Search with RAG optimization\n",
    "This document illustrates an example workflow for how to optimize Azure AI Search for RAG use cases to enhance the quality of document search. \n",
    "\n",
    "# Objective\n",
    "See if your RAG app's quality metrics improve using only the capabilities of Azure AI Search\n",
    "- Enhanced Vector (text-embedding3-large)\n",
    "- Multivector\n",
    "- BM25 + Vector\n",
    "- BM25 + Vector + Semantic Reranking\n",
    "- BM25 + Vector + Semantic Reranking + Query Rewrite\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "For a dependency installation, run the code below to install the packages required to run it. \n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Set up your environment\n",
    "Git clone the repository to your local machine. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.search.documents import SearchItemPaged\n",
    "from openai import AzureOpenAI\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.models import (\n",
    "    VectorizedQuery,\n",
    "    SearchScoreThreshold,\n",
    "    VectorSimilarityThreshold,\n",
    "    QueryType, \n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryDebugMode\n",
    ")\n",
    "from azure.search.documents import SearchClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)   \n",
    "\n",
    "\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai_api_version = os.getenv(\"AZURE_OPENAI_CHAT_API_VERSION\")\n",
    "ada002_deployment = os.getenv(\"AZURE_OPENAI_ADA002_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "large3_deployment = os.getenv(\"AZURE_OPENAI_3_LARGE_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "gpt_chat_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "ai_project_conn_str = os.getenv(\"AZURE_AI_PROJECT_CONN_STR\")\n",
    "\n",
    "QUERIES_FILE = \"data/rag_sample_qna_ko.jsonl\"\n",
    "\n",
    "print(f\"search_endpoint: {search_endpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_results(results: SearchItemPaged[dict]):\n",
    "    semantic_answers = results.get_answers()\n",
    "    if semantic_answers:\n",
    "        for answer in semantic_answers:\n",
    "            if answer.highlights:\n",
    "                print(f\"Semantic Answer: {answer.highlights}\")\n",
    "            else:\n",
    "                print(f\"Semantic Answer: {answer.text}\")\n",
    "            print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
    "\n",
    "    for result in results:\n",
    "        # print(f\"Title: {result['title']}\")  \n",
    "        print(f\"Score: {result['@search.score']}\")\n",
    "        if result.get('@search.reranker_score'):\n",
    "            print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "        print(f\"Content: {result['content']}\")  \n",
    "        # print(f\"Category: {result['new_product_name']}\\n\")\n",
    "\n",
    "        captions = result[\"@search.captions\"]\n",
    "        if captions:\n",
    "            caption = captions[0]\n",
    "            if caption.highlights:\n",
    "                print(f\"Caption: {caption.highlights}\\n\")\n",
    "            else:\n",
    "                print(f\"Caption: {caption.text}\\n\")\n",
    "        print(\"-\" * 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_client = AzureOpenAI(\n",
    "    azure_deployment=ada002_deployment,\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "embed3_client = AzureOpenAI(\n",
    "    azure_deployment=large3_deployment,\n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint=openai_endpoint,\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "search_client = SearchClient(endpoint=search_endpoint, index_name=index_name, credential=AzureKeyCredential(admin_key))\n",
    "\n",
    "with open('main_prompt_plain.txt', 'r') as file:\n",
    "    prompt_template = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEMANTIC, HYBRID, RERANKER, REWRITE Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class SearchType(Enum):   \n",
    "    SEMANTIC = \"semantic\"\n",
    "    HYBRID = \"hybrid\"\n",
    "    SEMANTIC_WITH_RERANKER = \"semantic_with_reranker\"\n",
    "    HYBRID_WITH_RERANKER = \"hybrid_with_reranker\"\n",
    "    SEMANTIC_WITH_RERANKER_REWRITE = \"semantic_with_reranker_rewrite\"\n",
    "    HYBRID_WITH_RERANKER_REWRITE = \"hybrid_with_reranker_rewrite\"\n",
    "    \n",
    "\n",
    "def search_with_type(search_type, embedding, category, type, query_text=None, vector_field=\"content_vector\", similarity_threshold=None):\n",
    "    results = None\n",
    "    vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=50, fields=vector_field, threshold=similarity_threshold\n",
    "                                )\n",
    "    if search_type == SearchType.SEMANTIC:\n",
    "        results = search_client.search(\n",
    "            vector_queries=[vector_query],\n",
    "            filter=f\"category eq '{category}' and type eq '{type}'\" if category and type else None,\n",
    "            top=3\n",
    "        )\n",
    "    elif search_type == SearchType.HYBRID:\n",
    "        results = search_client.search(\n",
    "            search_text=query_text,\n",
    "            vector_queries=[vector_query],\n",
    "            filter=f\"category eq '{category}' and type eq '{type}'\" if category and type else None,\n",
    "            top=3\n",
    "        )\n",
    "    elif search_type == SearchType.HYBRID_WITH_RERANKER:        \n",
    "        results = search_client.search(\n",
    "            search_text=query_text,\n",
    "            # search_text=None, # use No-BM25 search\n",
    "            vector_queries=[vector_query],\n",
    "            filter=f\"category eq '{category}' and type eq '{type}'\" if category and type else None,\n",
    "            query_type=QueryType.SEMANTIC,\n",
    "            semantic_configuration_name=\"my-semantic-config\",\n",
    "            # https://learn.microsoft.com/en-us/azure/search/semantic-how-to-query-rewrite\n",
    "            query_language=\"ko-KR\",\n",
    "            query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "            query_answer=QueryAnswerType.EXTRACTIVE,    \n",
    "            top=3\n",
    "        )\n",
    "    elif search_type == SearchType.HYBRID_WITH_RERANKER_REWRITE:\n",
    "        results = search_client.search(\n",
    "            # search_text=query_text,\n",
    "            # Semantic search query rewrite is not available for this service.\n",
    "            vector_queries=[vector_query],\n",
    "            filter=f\"category eq '{category}' and type eq '{type}'\" if category and type else None,\n",
    "            query_type=QueryType.SEMANTIC,\n",
    "            semantic_configuration_name=\"my-semantic-config\",\n",
    "            # https://learn.microsoft.com/en-us/azure/search/semantic-how-to-query-rewrite\n",
    "            query_language=\"ko-KR\",\n",
    "            query_rewrites=\"generative|count-5\",\n",
    "            debug=QueryDebugMode.QUERY_REWRITES,\n",
    "            query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "            query_answer=QueryAnswerType.EXTRACTIVE,    \n",
    "            top=3\n",
    "            \n",
    "    )\n",
    "    return results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_search_result(search_type, embedding_model, search_result_file_name, line_num, similarity_threshold=None):\n",
    "    def get_embedding(query):\n",
    "        return embed_client.embeddings.create(input=[query], model=embedding_model).data[0].embedding\n",
    "\n",
    "    query_document = []\n",
    "\n",
    "    with open(QUERIES_FILE, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            # initialize the list to store documents for each query\n",
    "            documents = []\n",
    "            if i >= line_num:  # Limit to processing questions\n",
    "                break\n",
    "            query = json.loads(line.strip())  # Parse each line as a JSON object\n",
    "            embedding = get_embedding(query['question'])\n",
    "            category = query['category']\n",
    "            type = query['type']\n",
    "            results = search_with_type(search_type, embedding, category, type, query['question'], vector_field=\"content_vector\", similarity_threshold=similarity_threshold) \n",
    "            #print_results(results)\n",
    "            \n",
    "            for res in results:\n",
    "                documents.append(res['content'])\n",
    "            \n",
    "            if len(documents) > 0:\n",
    "                document_content = \"\\n\".join(documents)\n",
    "            else:\n",
    "                document_content = \"No documents found.\"\n",
    "            query_document.append({\"query\": query['question'], \"document_content\": document_content})\n",
    "    \n",
    "    with open(f'{search_result_file_name}', 'w') as outfile:\n",
    "        json.dump(query_document, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the search results for each search method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_QUESTIONS = 20\n",
    "#similarity_threshold = VectorSimilarityThreshold(value=0.78)\n",
    "similarity_threshold = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ada002] SEMANTIC Search\n",
    "print(\"=== [ada002] SEMANTIC Search ===\")\n",
    "save_search_result(SearchType.SEMANTIC, ada002_deployment, 'result_search/queries_contexts_ada2_semantic.json', NUMBER_OF_QUESTIONS, similarity_threshold=similarity_threshold)\n",
    "\n",
    "# [ada002] HYBRID Search\n",
    "print(\"=== [ada002] HYBRID Search ===\")\n",
    "save_search_result(SearchType.HYBRID, ada002_deployment, 'result_search/queries_contexts_ada2_hybrid.json', NUMBER_OF_QUESTIONS, similarity_threshold=similarity_threshold)\n",
    "\n",
    "# [large3] HYBRID Search\n",
    "print(\"=== [large3] HYBRID Search ===\")\n",
    "save_search_result(SearchType.HYBRID, large3_deployment, 'result_search/queries_contexts_large3_hybrid.json', NUMBER_OF_QUESTIONS, similarity_threshold=similarity_threshold)\n",
    "\n",
    "# [large3] HYBRID + RERANKER Search\n",
    "print(\"=== [large3] HYBRID + RERANKER Search ===\")\n",
    "save_search_result(SearchType.HYBRID_WITH_RERANKER, large3_deployment, 'result_search/queries_contexts_large3_hybrid_reranker.json', NUMBER_OF_QUESTIONS, similarity_threshold=similarity_threshold)\n",
    "\n",
    "# [large3] HYBRID + RERANKER + REWRITE Search\n",
    "print(\"=== [large3] HYBRID + RERANKER + REWRITE Search ===\")\n",
    "save_search_result(SearchType.HYBRID_WITH_RERANKER_REWRITE, large3_deployment, 'result_search/queries_contexts_large3_hybrid_reranker_rewrite.json', NUMBER_OF_QUESTIONS, similarity_threshold=similarity_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get answer with RAG orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_response_use_llm(search_result_file_name, response_file_name):\n",
    "    def process_llm(query, document_content):\n",
    "        openai_client = AzureOpenAI(\n",
    "        azure_deployment=gpt_chat_deployment,\n",
    "        api_version=openai_api_version,\n",
    "        azure_endpoint=openai_endpoint,\n",
    "        api_key=openai_api_key,\n",
    "    )\n",
    "\n",
    "        prompt = prompt_template.replace(\"{question}\", query)\n",
    "        prompt = prompt.replace(\"{document}\", document_content)\n",
    "        response = openai_client.chat.completions.create(\n",
    "        model=gpt_chat_deployment,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        return answer\n",
    "\n",
    "    with open(f'{search_result_file_name}', 'r') as f:\n",
    "        queries_document = json.load(f)\n",
    "\n",
    "    query_answers_contexts = []\n",
    "\n",
    "    for query_doc in queries_document:\n",
    "        query = query_doc['query']\n",
    "        document_content = query_doc['document_content']\n",
    "        answer = process_llm(query, document_content) \n",
    "    # print(f\"Query: {query}\\nAnswer: {answer}\\n\")\n",
    "\n",
    "        query_answers_contexts.append({\n",
    "        \"query\": query,\n",
    "        \"document_content\": document_content,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "    with open(f'{response_file_name}', 'w') as outfile:\n",
    "        for item in query_answers_contexts:\n",
    "            json.dump(item, outfile, ensure_ascii=False)\n",
    "            outfile.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [ada002] SEMANTIC Search\n",
    "# print(\"=== [ada002] SEMANTIC Search ===\")\n",
    "# save_response_use_llm('result_search/queries_contexts_ada2_semantic.json', 'result_response/queries_responses_ada2_semantic.jsonl')\n",
    "\n",
    "# # [ada002] HYBRID Search\n",
    "# print(\"=== [ada002] HYBRID Search ===\")\n",
    "# save_response_use_llm('result_search/queries_contexts_ada2_hybrid.json', 'result_response/queries_responses_ada2_hybrid.jsonl')\n",
    "\n",
    "# # [large3] HYBRID Search\n",
    "# print(\"=== [large3] HYBRID Search ===\")\n",
    "# save_response_use_llm('result_search/queries_contexts_large3_hybrid.json', 'result_response/queries_responses_large3_hybrid.jsonl')\n",
    "\n",
    "# [large3] HYBRID + RERANKER Search\n",
    "print(\"=== [large3] HYBRID + RERANKER Search ===\")\n",
    "save_response_use_llm('result_search/queries_contexts_large3_hybrid_reranker.json', 'result_response/queries_responses_large3_hybrid_reranker.jsonl')\n",
    "\n",
    "# [large3] HYBRID + RERANKER + REWRITE Search\n",
    "print(\"=== [large3] HYBRID + RERANKER + REWRITE Search ===\")\n",
    "save_response_use_llm('result_search/queries_contexts_large3_hybrid_reranker_rewrite.json', 'result_response/queries_responses_hybrid_reranker_rewrite.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate by Azure AI Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from azure.ai.evaluation import (\n",
    "    evaluate, \n",
    "    FluencyEvaluator, \n",
    "    GroundednessEvaluator, \n",
    "    RelevanceEvaluator, \n",
    "    CoherenceEvaluator,\n",
    "    SimilarityEvaluator,\n",
    "\n",
    ")\n",
    "\n",
    "column_mapping = {\n",
    "    \"query\": \"${data.query}\",\n",
    "    \"context\": \"${data.document_content}\",\n",
    "    \"response\": \"${data.answer}\"\n",
    "}\n",
    "\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": openai_endpoint,\n",
    "    \"api_key\": openai_api_key,\n",
    "    \"azure_deployment\": gpt_chat_deployment,\n",
    "    \"api_version\": openai_api_version,\n",
    "}\n",
    "\n",
    "\n",
    "fluencyEvaluator = FluencyEvaluator(model_config)\n",
    "groundednessEvaluator = GroundednessEvaluator(model_config)\n",
    "relevanceEvaluator = RelevanceEvaluator(model_config)\n",
    "coherenceEvaluator = CoherenceEvaluator(model_config)\n",
    "similarityEvaluator = SimilarityEvaluator(model_config)\n",
    "\n",
    "azure_ai_project_conn_str = os.environ.get(\"AZURE_AI_PROJECT_CONN_STR\")\n",
    "subscription_id = azure_ai_project_conn_str.split(\";\")[1]\n",
    "resource_group_name = azure_ai_project_conn_str.split(\";\")[2]\n",
    "project_name = azure_ai_project_conn_str.split(\";\")[3]\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": subscription_id,\n",
    "    \"resource_group_name\": resource_group_name,\n",
    "    \"project_name\": project_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_evaluator(eval_name, response_file_name, eval_output_file_name):\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "    \n",
    "    result = evaluate(\n",
    "    evaluation_name=f\"rag_opt_{eval_name}_{current_time}\",\n",
    "    data=f\"{response_file_name}\",\n",
    "    evaluators={\n",
    "        # \"fluency\": fluencyEvaluator,\n",
    "        # \"groundedness\": groundednessEvaluator,\n",
    "        \"relevance\": relevanceEvaluator,\n",
    "        # \"coherence\": coherenceEvaluator,\n",
    "        # \"similarity\": similarityEvaluator,\n",
    "    },\n",
    "    evaluator_config={\n",
    "        # \"fluency\": {\n",
    "        #     \"column_mapping\": column_mapping\n",
    "        # },\n",
    "        # \"groundedness\": {\n",
    "        #     \"column_mapping\": column_mapping\n",
    "        # },\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": column_mapping\n",
    "        },\n",
    "        # \"coherence\": {\n",
    "        #     \"column_mapping\": column_mapping\n",
    "        # },\n",
    "        # \"similarity\": {\n",
    "        #     \"column_mapping\": column_mapping\n",
    "        # }\n",
    "    },\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    output_path=eval_output_file_name\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ada002] SEMANTIC Search\n",
    "print(\"=== [ada002] SEMANTIC Search ===\")\n",
    "azure_evaluator('ada2_semantic', 'result_response/queries_responses_ada2_semantic.jsonl', 'result_eval/eval_ada2_semantic.json')\n",
    "\n",
    "# [ada002] HYBRID Search\n",
    "print(\"=== [ada002] HYBRID Search ===\")\n",
    "azure_evaluator('ada2_hybrid', 'result_response/queries_responses_ada2_hybrid.jsonl', 'result_eval/eval_ada2_hybrid.json')\n",
    "\n",
    "# [large3] HYBRID Search\n",
    "print(\"=== [large3] HYBRID Search ===\")\n",
    "azure_evaluator('large3_hybrid', 'result_response/queries_responses_large3_hybrid.jsonl', 'result_eval/eval_large3_hybrid.json')\n",
    "\n",
    "# [large3] HYBRID + RERANKER Search\n",
    "print(\"=== [large3] HYBRID + RERANKER Search ===\")\n",
    "azure_evaluator('large3_hybrid_reranker', 'result_response/queries_responses_large3_hybrid_reranker.jsonl', 'result_eval/eval_large3_hybrid_reranker.json')\n",
    "\n",
    "# [large3] HYBRID + RERANKER + REWRITE Search\n",
    "print(\"=== [large3] HYBRID + RERANKER + REWRITE Search ===\")\n",
    "azure_evaluator('large3_hybrid_reranker_rewrite', 'result_response/queries_responses_large3_hybrid_reranker_rewrite.jsonl', 'result_eval/eval_hybrid_reranker_rewrite.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the evaluation results from the JSON file\n",
    "with open('result_eval/eval_ada2_semantic.json', 'r') as f:\n",
    "    evaluation_results = json.load(f)\n",
    "\n",
    "# Extract the relevance scores\n",
    "relevance_scores = [row['outputs.relevance.relevance'] for row in evaluation_results['rows']]\n",
    "\n",
    "# Plot the relevance scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(relevance_scores, bins=5, range=(1, 5), edgecolor='black')\n",
    "plt.title('Relevance Scores Distribution')\n",
    "plt.xlabel('Relevance Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Relevance Scores of 3 or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_relevance_queries = [(index, row['inputs.query']) for index, row in enumerate(evaluation_results['rows']) if row['outputs.relevance.relevance'] <= 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_relevance_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query_vector_sematic_reranker(embedding, category, type, query_text = None, vector_field=\"content_vector\"):\n",
    "    vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=50, fields=vector_field,\n",
    "                                #    threshold=VectorSimilarityThreshold(value=0.84)\n",
    "                                   )\n",
    "\n",
    "    results = search_client.search(\n",
    "        search_text=query_text,\n",
    "        vector_queries=[vector_query],\n",
    "        filter=f\"category eq '{category}' and type eq '{type}'\",\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name=\"my-semantic-config\",\n",
    "        query_language=\"en\",\n",
    "        query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "        query_answer=QueryAnswerType.EXTRACTIVE,    \n",
    "        top=3\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid + Vector Search (with Query Rewrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query_vector_sematic_reranker_query_rewrite(embedding, category, type, query_text = None, vector_field=\"content_vector\"):\n",
    "    vector_query = VectorizedQuery(vector=embedding, k_nearest_neighbors=50, fields=vector_field, \n",
    "                                   # threshold=VectorSimilarityThreshold(value=0.78)\n",
    "                                   )\n",
    "\n",
    "    results = search_client.search(\n",
    "        search_text=query_text,\n",
    "        # search_text=None, # use No-BM25 search\n",
    "        vector_queries=[vector_query],\n",
    "        filter=f\"category eq '{category}' and type eq '{type}'\",\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name=\"my-semantic-config\",\n",
    "        query_language=\"ko-KR\",\n",
    "        query_rewrites=\"generative|count-5\",\n",
    "        debug=QueryDebugMode.QUERY_REWRITES,\n",
    "        query_caption=QueryCaptionType.EXTRACTIVE,\n",
    "        query_answer=QueryAnswerType.EXTRACTIVE,    \n",
    "        top=3\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
