{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Open AI o1 multi-modal Test\n",
    "The following sample shows the most basic way to use the o1(GA) with Vision model with code.\n",
    "\n",
    "> ✨ ***Note*** <br>\n",
    "> Please check the supported models and API version before you get started - https://azure.microsoft.com/en-us/blog/announcing-the-o1-model-in-azure-openai-service-multimodal-reasoning-with-astounding-analysis/?msockid=388843f556c46b710353575a57e66a9a\n",
    "\n",
    "## Prerequisites\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "For a dependency installation, run the code below to install the packages required to run it. \n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Set up your environment\n",
    "Git clone the repository to your local machine. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## 🔨 Current Support and Limitations (as of 2025-01-06) \n",
    "- In order to use the image processing, please understand that you must call the o1 using API at this moment.\n",
    "- GA model version is 2024-12-17. Please check the deployed model version before calling\n",
    "- Model o1 is enabled only for api versions **2024-12-01-preview** and later. Please set the api version currently. \n",
    "- Check the region o1 supported - https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#o1-modelsopen ai rest\n",
    "- Check the API version o1 supported - https://learn.microsoft.com/en-us/azure/ai-services/openai/reference-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: python31015jvsc74a57bd07fae5fd5097eba353202a8ff671bfdb53a1767393571418b923386fbe14d03af\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "module_path = \"../util\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "from common import check_kernel\n",
    "check_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 o1 multimodal with image url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afh/code/Azure_OpenAI_samples/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import base64\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, EnvironmentCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from io import BytesIO\n",
    "import gradio as gr\n",
    "load_dotenv(override=True)\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "#azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\", \"\") if len(os.getenv(\"AZURE_OPENAI_KEY\", \"\")) > 0 else None\n",
    "azure_openai_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\")) > 0 else None\n",
    "kv_secret_name = os.getenv(\"KEY_VAULT_SECRET_NAME\")\n",
    "tenant_id = os.getenv(\"AZURE_TENANT_ID\")\n",
    "\n",
    "\n",
    "# Use DefaultAzureCredential to authenticate with Azure Key Vault\n",
    "# credential = DefaultAzureCredential()\n",
    "credential = InteractiveBrowserCredential(tenant_id=tenant_id)\n",
    "\n",
    "key_vault_url = os.getenv(\"AZURE_KEY_VAULT_URL\")\n",
    "key_vault_secret_name = os.getenv(\"AZURE_KEY_VAULT_SECRET_NAME\")\n",
    "\n",
    "kv_client = SecretClient(vault_url=key_vault_url, credential=credential)\n",
    "\n",
    "# Retrieve the OpenAI API key from Key Vault\n",
    "azure_openai_key = kv_client.get_secret(key_vault_secret_name).value\n",
    "\n",
    "# Initialize the AzureOpenAI client with the retrieved key\n",
    "try:\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key,\n",
    "        api_version=aoai_api_version\n",
    "    )\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Ams6s31VOVX2AGrzFyFFVLkIYcijB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It’s a simple vertical flow diagram showing data (“Benchmark data”) entering a “Prompt flow” box. Inside that box, there are three steps in sequence: “Input,” the pink “Semantic Kernel,” and then “Output.” From there, the flow continues downward to a final box labeled “Results and metrics.” Essentially, it illustrates a pipeline where benchmark data feeds into prompt processing by the Semantic Kernel to produce output and, ultimately, measurable results.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1736211106, model='o1-2024-12-17', object='chat.completion', service_tier=None, system_fingerprint='fp_db33bdfc5e', usage=CompletionUsage(completion_tokens=425, prompt_tokens=918, total_tokens=1343, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=320, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'indirect_attack': {'filtered': False, 'detected': False}, 'custom_blocklists': {'filtered': False, 'details': []}}}, {'prompt_index': 1, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'custom_blocklists': {'filtered': False, 'details': []}}}])\n",
      "It’s a simple vertical flow diagram showing data (“Benchmark data”) entering a “Prompt flow” box. Inside that box, there are three steps in sequence: “Input,” the pink “Semantic Kernel,” and then “Output.” From there, the flow continues downward to a final box labeled “Results and metrics.” Essentially, it illustrates a pipeline where benchmark data feeds into prompt processing by the Semantic Kernel to produce output and, ultimately, measurable results.\n",
      "Usage Information:\n",
      "Cached Tokens: 0\n",
      "Completion Tokens: 425\n",
      "Prompt Tokens: 918\n",
      "Total Tokens: 1343\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=azure_openai_deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Describe this picture:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"https://devblogs.microsoft.com/semantic-kernel/wp-content/uploads/sites/78/2023/09/semantic-kernel-in-prompt-flow-1.png\"\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    \n",
    ")\n",
    "print(response)\n",
    "print(response.choices[0].message.content)\n",
    "print(\"Usage Information:\")\n",
    "print(f\"Cached Tokens: {response.usage.prompt_tokens_details.cached_tokens}\")\n",
    "print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Total Tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 o1 multimodal with local image (base64 encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
    "\n",
    "# Example usage\n",
    "image_path = './images/semantic-kernel-in-prompt-flow-1.png'\n",
    "data_url = local_image_to_data_url(image_path)\n",
    "#print(\"Data URL:\", data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Amd0V1QeEmGbu1u9PbiW23TuO0kr9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It is a simple, vertical flowchart showing how data moves through a “prompt flow” to produce results. At the top, a rounded rectangle labeled “Benchmark data” feeds into a larger box titled “Prompt flow.” Inside that box, the order is:  \\n• A smaller rectangle labeled “Input,”  \\n• An arrow pointing down to a magenta oval labeled “Semantic Kernel,”  \\n• Another arrow pointing down to a smaller rectangle labeled “Output.”  \\nFrom there, an arrow leads to a rounded rectangle at the bottom labeled “Results and metrics.” The overall diagram visually represents the flow from benchmark data in, through the semantic kernel, and out to final results and measurements.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1736153051, model='o1-2024-12-17', object='chat.completion', service_tier=None, system_fingerprint='fp_db33bdfc5e', usage=CompletionUsage(completion_tokens=662, prompt_tokens=918, total_tokens=1580, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=512, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'indirect_attack': {'filtered': False, 'detected': False}, 'custom_blocklists': {'filtered': False, 'details': []}}}, {'prompt_index': 1, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'custom_blocklists': {'filtered': False, 'details': []}}}])\n",
      "It is a simple, vertical flowchart showing how data moves through a “prompt flow” to produce results. At the top, a rounded rectangle labeled “Benchmark data” feeds into a larger box titled “Prompt flow.” Inside that box, the order is:  \n",
      "• A smaller rectangle labeled “Input,”  \n",
      "• An arrow pointing down to a magenta oval labeled “Semantic Kernel,”  \n",
      "• Another arrow pointing down to a smaller rectangle labeled “Output.”  \n",
      "From there, an arrow leads to a rounded rectangle at the bottom labeled “Results and metrics.” The overall diagram visually represents the flow from benchmark data in, through the semantic kernel, and out to final results and measurements.\n",
      "Usage Information:\n",
      "Cached Tokens: 0\n",
      "Completion Tokens: 662\n",
      "Prompt Tokens: 918\n",
      "Total Tokens: 1580\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=azure_openai_deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Describe this picture:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": data_url \n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    \n",
    ")\n",
    "print(response)\n",
    "print(response.choices[0].message.content)\n",
    "print(\"Usage Information:\")\n",
    "print(f\"Cached Tokens: {response.usage.prompt_tokens_details.cached_tokens}\")\n",
    "print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Total Tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 o1 structured output \n",
    "Structured outputs make a model follow a JSON Schema definition that you provide as part of your inference API call. This is in contrast to the older JSON mode feature, which guaranteed valid JSON would be generated, but was unable to ensure strict adherence to the supplied schema. Structured outputs is recommended for function calling, extracting structured data, and building complex multi-step workflows.\n",
    "\n",
    "### Supported models (as of 2025-01-06) \n",
    "- o1 version: 2024-12-17\n",
    "- gpt-4o-mini version: 2024-07-18\n",
    "- gpt-4o version: 2024-08-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Ams8cRyrea6lIGWyVb5zQwBjSuzFl', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_h4TRCXiPdclXyzbc2hPBoHY4', function=Function(arguments='{\"weather_location\":\"Seoul\",\"country_location\":\"South Korea\",\"country_language\":\"Korean\"}', name='GetInformations'), type='function')]), content_filter_results={})], created=1736211214, model='o1-2024-12-17', object='chat.completion', service_tier=None, system_fingerprint='fp_db33bdfc5e', usage=CompletionUsage(completion_tokens=112, prompt_tokens=76, total_tokens=188, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=64, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
      "Function(arguments='{\"weather_location\":\"Seoul\",\"country_location\":\"South Korea\",\"country_language\":\"Korean\"}', name='GetInformations')\n",
      "{\"weather_location\":\"Seoul\",\"country_location\":\"South Korea\",\"country_language\":\"Korean\"}\n",
      "Usage Information:\n",
      "Cached Tokens: 0\n",
      "Completion Tokens: 112\n",
      "Prompt Tokens: 76\n",
      "Total Tokens: 188\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class GetInformations(BaseModel):\n",
    "    weather_location: str\n",
    "    country_location: str\n",
    "    country_language: str\n",
    "\n",
    "\n",
    "tools = [openai.pydantic_function_tool(GetInformations)]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=azure_openai_deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Hello, what is the current weather for the capital of South Korea?\"\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    tools=tools\n",
    ")\n",
    "print(response)\n",
    "print(response.choices[0].message.tool_calls[0].function)\n",
    "print(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "print(\"Usage Information:\")\n",
    "print(f\"Cached Tokens: {response.usage.prompt_tokens_details.cached_tokens}\")\n",
    "print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Total Tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"id\": \"chatcmpl-Ams8cRyrea6lIGWyVb5zQwBjSuzFl\",\n",
      "   \"choices\": [\n",
      "      {\n",
      "         \"finish_reason\": \"tool_calls\",\n",
      "         \"index\": 0,\n",
      "         \"logprobs\": null,\n",
      "         \"message\": {\n",
      "            \"content\": null,\n",
      "            \"refusal\": null,\n",
      "            \"role\": \"assistant\",\n",
      "            \"audio\": null,\n",
      "            \"function_call\": null,\n",
      "            \"tool_calls\": [\n",
      "               {\n",
      "                  \"id\": \"call_h4TRCXiPdclXyzbc2hPBoHY4\",\n",
      "                  \"function\": {\n",
      "                     \"arguments\": \"{\\\"weather_location\\\":\\\"Seoul\\\",\\\"country_location\\\":\\\"South Korea\\\",\\\"country_language\\\":\\\"Korean\\\"}\",\n",
      "                     \"name\": \"GetInformations\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "               }\n",
      "            ]\n",
      "         },\n",
      "         \"content_filter_results\": {}\n",
      "      }\n",
      "   ],\n",
      "   \"created\": 1736211214,\n",
      "   \"model\": \"o1-2024-12-17\",\n",
      "   \"object\": \"chat.completion\",\n",
      "   \"service_tier\": null,\n",
      "   \"system_fingerprint\": \"fp_db33bdfc5e\",\n",
      "   \"usage\": {\n",
      "      \"completion_tokens\": 112,\n",
      "      \"prompt_tokens\": 76,\n",
      "      \"total_tokens\": 188,\n",
      "      \"completion_tokens_details\": {\n",
      "         \"audio_tokens\": 0,\n",
      "         \"reasoning_tokens\": 64,\n",
      "         \"accepted_prediction_tokens\": 0,\n",
      "         \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "         \"audio_tokens\": 0,\n",
      "         \"cached_tokens\": 0\n",
      "      }\n",
      "   },\n",
      "   \"prompt_filter_results\": [\n",
      "      {\n",
      "         \"prompt_index\": 0,\n",
      "         \"content_filter_results\": {\n",
      "            \"hate\": {\n",
      "               \"filtered\": false,\n",
      "               \"severity\": \"safe\"\n",
      "            },\n",
      "            \"jailbreak\": {\n",
      "               \"filtered\": false,\n",
      "               \"detected\": false\n",
      "            },\n",
      "            \"self_harm\": {\n",
      "               \"filtered\": false,\n",
      "               \"severity\": \"safe\"\n",
      "            },\n",
      "            \"sexual\": {\n",
      "               \"filtered\": false,\n",
      "               \"severity\": \"safe\"\n",
      "            },\n",
      "            \"violence\": {\n",
      "               \"filtered\": false,\n",
      "               \"severity\": \"safe\"\n",
      "            }\n",
      "         }\n",
      "      }\n",
      "   ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.model_dump_json(indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 o1 playground sample  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "def o1_webapp_gradio(pil_image, prompt):\n",
    "    \"\"\"\n",
    "    o1 model integration for analyzing images.\n",
    "    \"\"\"\n",
    "    # Save image to an in-memory buffer\n",
    "    buffer = BytesIO()\n",
    "    pil_image.save(buffer, format=\"JPEG\")\n",
    "    buffer.seek(0)\n",
    "\n",
    "    # Encode the image to base64\n",
    "    image_data = base64.b64encode(buffer.read()).decode('utf-8')\n",
    "    image_url = f\"data:image/jpeg;base64,{image_data}\"\n",
    "\n",
    "    # Construct the messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                { \n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url \n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Call the Azure OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=azure_openai_deployment_name,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://cdn-dynmedia-1.microsoft.com/is/image/microsoftcorp/UHFbanner-MSlogo?fmt=png-alpha&bfc=off&qlt=100,1\"\n",
    "logo = \"<center> <img src= {} width=100px></center>\".format(image_url)\n",
    "title = \"o1 model Playground\"\n",
    "\n",
    "inputs = [\n",
    "    gr.Image(type=\"pil\", label=\"Your image\"),\n",
    "    gr.Text(label=\"Your prompt\", value=\"Describe this image:\"),\n",
    "]\n",
    "outputs = [\n",
    "    gr.Text(label=f\"{azure_openai_deployment_name} results\"),\n",
    "]\n",
    "theme = \"gradio/monochrome\"  # https://huggingface.co/spaces/gradio/theme-gallery\n",
    "\n",
    "gp4o_webapp = gr.Interface(\n",
    "    fn=o1_webapp_gradio,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    description=logo,\n",
    "    title=title,\n",
    "    theme=theme,\n",
    ")\n",
    "\n",
    "gp4o_webapp.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
