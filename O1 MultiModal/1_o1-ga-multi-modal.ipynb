{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Open AI o1 multi-modal Test\n",
    "The following sample shows the most basic way to use the o1(GA) with Vision model with code.\n",
    "\n",
    "> ‚ú® ***Note*** <br>\n",
    "> Please check the supported models and API version before you get started - https://azure.microsoft.com/en-us/blog/announcing-the-o1-model-in-azure-openai-service-multimodal-reasoning-with-astounding-analysis/?msockid=388843f556c46b710353575a57e66a9a\n",
    "\n",
    "## Prerequisites\n",
    "Configure a Python virtual environment for 3.10 or later: \n",
    " 1. open the Command Palette (Ctrl+Shift+P).\n",
    " 1. Search for Python: Create Environment.\n",
    " 1. select Venv / Conda and choose where to create the new environment.\n",
    " 1. Select the Python interpreter version. Create with version 3.10 or later.\n",
    "\n",
    "For a dependency installation, run the code below to install the packages required to run it. \n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "## Set up your environment\n",
    "Git clone the repository to your local machine. \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/hyogrin/Azure_OpenAI_samples.git\n",
    "```\n",
    "\n",
    "Create an .env file based on the .env-sample file. Copy the new .env file to the folder containing your notebook and update the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "## üî® Current Support and Limitations (as of 2025-01-06) \n",
    "- In order to use the image processing, please understand that you must call the o1 using API at this moment.\n",
    "- GA model version is 2024-12-17. Please check the deployed model version before calling\n",
    "- Model o1 is enabled only for api versions **2024-12-01-preview** and later. Please set the api version currently.¬†\n",
    "- Check the region o1 supported - https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#o1-modelsopen ai rest\n",
    "- Check the API version o1 supported - https://learn.microsoft.com/en-us/azure/ai-services/openai/reference-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Kernel: python31015jvsc74a57bd07fae5fd5097eba353202a8ff671bfdb53a1767393571418b923386fbe14d03af\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "module_path = \"../util\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "from common import check_kernel\n",
    "check_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ o1 multimodal with image url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential, EnvironmentCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "load_dotenv(override=True)\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "#azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\", \"\") if len(os.getenv(\"AZURE_OPENAI_KEY\", \"\")) > 0 else None\n",
    "azure_openai_deployment_name = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-ada-002\")\n",
    "aoai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\") if len(os.getenv(\"AZURE_OPENAI_API_VERSION\", \"\")) > 0 else None\n",
    "kv_secret_name = os.getenv(\"KEY_VAULT_SECRET_NAME\")\n",
    "tenant_id = os.getenv(\"AZURE_TENANT_ID\")\n",
    "\n",
    "\n",
    "# Use DefaultAzureCredential to authenticate with Azure Key Vault\n",
    "# credential = DefaultAzureCredential()\n",
    "credential = InteractiveBrowserCredential(tenant_id=tenant_id)\n",
    "\n",
    "key_vault_url = os.getenv(\"AZURE_KEY_VAULT_URL\")\n",
    "key_vault_secret_name = os.getenv(\"AZURE_KEY_VAULT_SECRET_NAME\")\n",
    "\n",
    "kv_client = SecretClient(vault_url=key_vault_url, credential=credential)\n",
    "\n",
    "# Retrieve the OpenAI API key from Key Vault\n",
    "azure_openai_key = kv_client.get_secret(key_vault_secret_name).value\n",
    "\n",
    "# Initialize the AzureOpenAI client with the retrieved key\n",
    "try:\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=azure_openai_endpoint,\n",
    "        api_key=azure_openai_key,\n",
    "        api_version=aoai_api_version\n",
    "    )\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AmdIPxuzTeTTcrVNjX2ojPHVqOFXo', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The diagram is a simple vertical flow chart. At the top is an oval labeled ‚ÄúBenchmark data,‚Äù with a downward arrow leading into a rectangular ‚ÄúPrompt flow‚Äù container. Inside that container, there are three key steps arranged vertically:\\n\\n1. A smaller box labeled ‚ÄúInput.‚Äù  \\n2. A large, rounded rectangle labeled ‚ÄúSemantic Kernel.‚Äù  \\n3. Another smaller box labeled ‚ÄúOutput.‚Äù  \\n\\nFinally, another downward arrow leaves the bottom of the ‚ÄúPrompt flow‚Äù container and points to an oval labeled ‚ÄúResults and metrics.‚Äù', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1736154161, model='o1-2024-12-17', object='chat.completion', service_tier=None, system_fingerprint='fp_db33bdfc5e', usage=CompletionUsage(completion_tokens=247, prompt_tokens=918, total_tokens=1165, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=128, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'indirect_attack': {'filtered': False, 'detected': False}, 'custom_blocklists': {'filtered': False, 'details': []}}}, {'prompt_index': 1, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'custom_blocklists': {'filtered': False, 'details': []}}}])\n",
      "The diagram is a simple vertical flow chart. At the top is an oval labeled ‚ÄúBenchmark data,‚Äù with a downward arrow leading into a rectangular ‚ÄúPrompt flow‚Äù container. Inside that container, there are three key steps arranged vertically:\n",
      "\n",
      "1. A smaller box labeled ‚ÄúInput.‚Äù  \n",
      "2. A large, rounded rectangle labeled ‚ÄúSemantic Kernel.‚Äù  \n",
      "3. Another smaller box labeled ‚ÄúOutput.‚Äù  \n",
      "\n",
      "Finally, another downward arrow leaves the bottom of the ‚ÄúPrompt flow‚Äù container and points to an oval labeled ‚ÄúResults and metrics.‚Äù\n",
      "Usage Information:\n",
      "Cached Tokens: 0\n",
      "Completion Tokens: 247\n",
      "Prompt Tokens: 918\n",
      "Total Tokens: 1165\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=azure_openai_deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Describe this picture:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"https://devblogs.microsoft.com/semantic-kernel/wp-content/uploads/sites/78/2023/09/semantic-kernel-in-prompt-flow-1.png\"\n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    \n",
    ")\n",
    "print(response)\n",
    "print(response.choices[0].message.content)\n",
    "print(\"Usage Information:\")\n",
    "print(f\"Cached Tokens: {response.usage.prompt_tokens_details.cached_tokens}\")\n",
    "print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Total Tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ o1 multimodal with local image (base64 encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from mimetypes import guess_type\n",
    "\n",
    "# Function to encode a local image into data URL \n",
    "def local_image_to_data_url(image_path):\n",
    "    # Guess the MIME type of the image based on the file extension\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
    "\n",
    "    # Read and encode the image file\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Construct the data URL\n",
    "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
    "\n",
    "# Example usage\n",
    "image_path = './images/semantic-kernel-in-prompt-flow-1.png'\n",
    "data_url = local_image_to_data_url(image_path)\n",
    "#print(\"Data URL:\", data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Amd0V1QeEmGbu1u9PbiW23TuO0kr9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It is a simple, vertical flowchart showing how data moves through a ‚Äúprompt flow‚Äù to produce results. At the top, a rounded rectangle labeled ‚ÄúBenchmark data‚Äù feeds into a larger box titled ‚ÄúPrompt flow.‚Äù Inside that box, the order is:  \\n‚Ä¢ A smaller rectangle labeled ‚ÄúInput,‚Äù  \\n‚Ä¢ An arrow pointing down to a magenta oval labeled ‚ÄúSemantic Kernel,‚Äù  \\n‚Ä¢ Another arrow pointing down to a smaller rectangle labeled ‚ÄúOutput.‚Äù  \\nFrom there, an arrow leads to a rounded rectangle at the bottom labeled ‚ÄúResults and metrics.‚Äù The overall diagram visually represents the flow from benchmark data in, through the semantic kernel, and out to final results and measurements.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1736153051, model='o1-2024-12-17', object='chat.completion', service_tier=None, system_fingerprint='fp_db33bdfc5e', usage=CompletionUsage(completion_tokens=662, prompt_tokens=918, total_tokens=1580, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=512, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'indirect_attack': {'filtered': False, 'detected': False}, 'custom_blocklists': {'filtered': False, 'details': []}}}, {'prompt_index': 1, 'content_filter_result': {'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}, 'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'custom_blocklists': {'filtered': False, 'details': []}}}])\n",
      "It is a simple, vertical flowchart showing how data moves through a ‚Äúprompt flow‚Äù to produce results. At the top, a rounded rectangle labeled ‚ÄúBenchmark data‚Äù feeds into a larger box titled ‚ÄúPrompt flow.‚Äù Inside that box, the order is:  \n",
      "‚Ä¢ A smaller rectangle labeled ‚ÄúInput,‚Äù  \n",
      "‚Ä¢ An arrow pointing down to a magenta oval labeled ‚ÄúSemantic Kernel,‚Äù  \n",
      "‚Ä¢ Another arrow pointing down to a smaller rectangle labeled ‚ÄúOutput.‚Äù  \n",
      "From there, an arrow leads to a rounded rectangle at the bottom labeled ‚ÄúResults and metrics.‚Äù The overall diagram visually represents the flow from benchmark data in, through the semantic kernel, and out to final results and measurements.\n",
      "Usage Information:\n",
      "Cached Tokens: 0\n",
      "Completion Tokens: 662\n",
      "Prompt Tokens: 918\n",
      "Total Tokens: 1580\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=azure_openai_deployment_name,\n",
    "    messages=[\n",
    "        { \"role\": \"user\", \"content\": [  \n",
    "            { \n",
    "                \"type\": \"text\", \n",
    "                \"text\": \"Describe this picture:\" \n",
    "            },\n",
    "            { \n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": data_url \n",
    "                }\n",
    "            }\n",
    "        ] } \n",
    "    ],\n",
    "    \n",
    ")\n",
    "print(response)\n",
    "print(response.choices[0].message.content)\n",
    "print(\"Usage Information:\")\n",
    "print(f\"Cached Tokens: {response.usage.prompt_tokens_details.cached_tokens}\")\n",
    "print(f\"Completion Tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Prompt Tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Total Tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
